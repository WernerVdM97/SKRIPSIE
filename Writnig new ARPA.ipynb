{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "'''\n",
    "import sys\n",
    "sys.path.append('Classes')\n",
    "from arpy import *\n",
    "'''\n",
    "import arpa\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prep cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1060 6GB\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45918515/45918515 [00:47<00:00, 958725.32it/s] \n"
     ]
    }
   ],
   "source": [
    "file = '../../rsc/train_counts.txt'\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "\n",
    "ngram_dict = {}\n",
    "for x in tqdm(first_read, total=num_lines, position=0, leave=True):\n",
    "    line = x.split('\\t')\n",
    "    r = int(line[-1])\n",
    "    ngram_dict[line[0]] = r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Prep NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  (fc3): Linear(in_features=4, out_features=3, bias=True)\n",
       "  (fc4): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 4)\n",
    "        #self.fc2 = nn.Linear(4, 4)\n",
    "        self.fc3 = nn.Linear(4, 3)\n",
    "        self.fc4 = nn.Linear(3, 1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        #x = torch.sigmoid(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x)) \n",
    "        x = torch.sigmoid(self.fc4(x)) \n",
    "        return x\n",
    "'''\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 3)\n",
    "        #self.fc2 = nn.Linear(4, 4)\n",
    "        self.fc3 = nn.Linear(3, 3)\n",
    "        self.fc4 = nn.Linear(3, 1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        #x = torch.sigmoid(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x)) \n",
    "        x = torch.sigmoid(self.fc4(x)) \n",
    "        return x\n",
    "'''\n",
    "net = Net().cuda()\n",
    "net.load_state_dict(torch.load('NN saves/4431_lr=0.03_MAE'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Write ARPA\n",
    "## NN with 4 inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19630106/19630106 [1:11:26<00:00, 4579.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#start = time.time()\n",
    "file = '../../rsc/unsmoothedLM.arpa'\n",
    "#file = '../../temp/small.arpa'\n",
    "first_read = open(file ,'r')\n",
    "new_file = open(\"../../rsc/nnLM.arpa\",\"w+\")\n",
    "#new_file = open('../../temp/nn_small.arpa' , 'w+')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "current_ngram_len = 0\n",
    "error = 0\n",
    "count = 0\n",
    "nn_input = torch.zeros(1, 4, dtype = torch.float, device = device)\n",
    "\n",
    "\n",
    "for x in tqdm(first_read, total=num_lines, position=0, leave=True):\n",
    "    if x == '\\\\end\\\\\\n':\n",
    "        current_ngram_len = -1\n",
    "        new_file.write(x)\n",
    "    elif x == '\\n':\n",
    "        new_file.write(x)\n",
    "    elif current_ngram_len < 3:\n",
    "        new_file.write(x)\n",
    "    elif current_ngram_len == 3:\n",
    "        #evaluate count\n",
    "        line = x.split('\\t')\n",
    "        r = ngram_dict[line[1][:-1]]\n",
    "        if r ==1 :\n",
    "            print('oops')\n",
    "\n",
    "        if r > 1 and r < 8: #only smooth values for r < 8\n",
    "            prob = 10**float(line[0])\n",
    "            ngram = line[1].split(' ')\n",
    "            ngram[2] = ngram[2][:-1]\n",
    "            count += 1\n",
    "            \n",
    "            ######setup nn input#######\n",
    "            nn_input[0][0] = ngram_dict[ngram[0] + ' ' + ngram[1]]  #prefix count\n",
    "            nn_input[0][1] = ngram_dict[line[1][:-1]]               #trigram count\n",
    "            nn_input[0][2] = ngram_dict[ngram[1] + ' ' + ngram[2]]  #backoff bigram count\n",
    "            nn_input[0][3] = ngram_dict[ngram[2]]                   #unigram count\n",
    "            nn_input = 1/nn_input\n",
    "\n",
    "            MLE = nn_input[0][0]/nn_input[0][1]\n",
    "            smoothed_prob  = net(nn_input)\n",
    "            '''\n",
    "            print(MLE)\n",
    "            print(prob)\n",
    "            print(smoothed_prob)\n",
    "            print(' ')\n",
    "            '''\n",
    "            if smoothed_prob > MLE:\n",
    "                #print('error ' + str(smoothed_prob[0]) + ' vs ' + str(prob) )\n",
    "                #print(r)\n",
    "                smoothed_prob = MLE\n",
    "                error += 1\n",
    "\n",
    "            logbase = math.log(smoothed_prob, 10)\n",
    "\n",
    "            #write\n",
    "            new_file.write('{:.7f}\\t{}\\n'.format(logbase, line[1][:-1]))\n",
    "        else:\n",
    "            new_file.write(x)\n",
    "            \n",
    "    if x == '\\\\1-grams:\\n':\n",
    "        current_ngram_len = 1\n",
    "    if x == '\\\\2-grams:\\n':\n",
    "        current_ngram_len = 2\n",
    "    if x == '\\\\3-grams:\\n':\n",
    "        current_ngram_len = 3\n",
    "        \n",
    "new_file.close()\n",
    "print('{:.2f}%'.format((error/count)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN with 3 inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = time.time()\n",
    "file = '../../rsc/old/nn_12-14.arpa'\n",
    "#file = '../../temp/small.arpa'\n",
    "first_read = open(file ,'r')\n",
    "new_file = open(\"../../rsc/nn_LM_r!=1.arpa\",\"w+\")\n",
    "#new_file = open('../../temp/nn_small.arpa' , 'w+')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "current_ngram_len = 0\n",
    "error = 0\n",
    "count = 0\n",
    "fuck = 0\n",
    "nn_input = torch.zeros(1, 3, dtype = torch.float, device = device)\n",
    "\n",
    "\n",
    "for x in tqdm(first_read, total=num_lines, position=0, leave=True):\n",
    "    if x == '\\\\end\\\\\\n':\n",
    "        current_ngram_len = -1\n",
    "        new_file.write(x)\n",
    "    elif x == '\\n':\n",
    "        new_file.write(x)\n",
    "    elif current_ngram_len < 2: #responsible for writing \\data\\ as well as \\1-grams:\n",
    "        new_file.write(x)\n",
    "    elif x == '\\\\3-grams:\\n':\n",
    "        new_file.write(x)\n",
    "    elif current_ngram_len == 2:#bigrams\n",
    "        #evaluate count\n",
    "        line = x.split('\\t')\n",
    "        \n",
    "        if len(line) == 2:\n",
    "            r = ngram_dict[line[1][:-1]]\n",
    "        elif len(line) == 3:\n",
    "            r = ngram_dict[line[1]]\n",
    "        \n",
    "            if r < 8 :\n",
    "                prob = 10**float(line[0])\n",
    "                logbase = math.log(prob*0.95, 10)\n",
    "\n",
    "                new_file.write('{:.7f}\\t{}\\t{:.8f}\\n'.format(logbase, line[1][:-1], -99))\n",
    "            else:\n",
    "                new_file.write('{:.7f}\\t{}\\t{:.8f}\\n'.format(float(line[0]), line[1][:-1], -99))\n",
    "\n",
    "    elif current_ngram_len == 3:#trigrams\n",
    "        #evaluate count\n",
    "        line = x.split('\\t')\n",
    "        r = ngram_dict[line[1][:-1]]\n",
    "\n",
    "        if r < 8 and r > 1: #only smooth values for r < 8, r = 1 does not exist for optim reasons\n",
    "            prob = 10**float(line[0])\n",
    "            ngram = line[1].split(' ')\n",
    "            ngram[2] = ngram[2][:-1]\n",
    "            count += 1\n",
    "            \n",
    "            ######setup nn input#######\n",
    "            MLE = ngram_dict[ngram[0] + ' ' + ngram[1]]/ngram_dict[line[1][:-1]]\n",
    "            MLE = 1/MLE\n",
    "            nn_input[0][0] = MLE                                    #prob\n",
    "            nn_input[0][1] = ngram_dict[ngram[1] + ' ' + ngram[2]]  #backoff bigram count\n",
    "            nn_input[0][2] = ngram_dict[ngram[2]]                   #unigram count\n",
    "            nn_input = 1/nn_input #corrects MLE\n",
    "            MLE = 1/MLE\n",
    "\n",
    "            #p = pnn - bias value\n",
    "            smoothed_prob  = net(nn_input) -0.00195\n",
    "            \n",
    "            if smoothed_prob > prob:\n",
    "                #print('error ' + str(smoothed_prob[0]) + ' vs ' + str(prob) )\n",
    "                #print(r)\n",
    "                error += 1\n",
    "                \n",
    "            #check for valid log(since bias can send it neg)\n",
    "            if smoothed_prob > MLE:\n",
    "                fuck +=1\n",
    "            else:\n",
    "\n",
    "                logbase = math.log(smoothed_prob, 10)\n",
    "\n",
    "            #write\n",
    "            new_file.write('{:.7f}\\t{}\\n'.format(logbase, line[1][:-1]))\n",
    "            \n",
    "    if x == '\\\\1-grams:\\n':\n",
    "        current_ngram_len = 1\n",
    "        new_file.write(x)\n",
    "    if x == '\\\\2-grams:\\n':\n",
    "        current_ngram_len = 2\n",
    "        new_file.write(x)\n",
    "    if x == '\\\\3-grams:\\n':\n",
    "        current_ngram_len = 3\n",
    "        \n",
    "new_file.close()\n",
    "print(error/count)\n",
    "print('fucks: ' + str(fuck))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 10125136/19630106 [00:05<00:04, 2002186.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.727726\t<s> AND BENNI\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19630106/19630106 [00:10<00:00, 1962939.51it/s]\n"
     ]
    }
   ],
   "source": [
    "#start = time.time()\n",
    "#file = '../../temp/test/12-14_bigrams_discounted.arpa'\n",
    "file = '../../rsc/unsmoothedLM.arpa'\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "prob = 0\n",
    "tot_prob = 0\n",
    "prob2 = 0\n",
    "tot_prob2 = 0\n",
    "prob3 = 0\n",
    "tot_prob3 = 0\n",
    "\n",
    "\n",
    "for x in tqdm(first_read, total=num_lines, position=0, leave=True):\n",
    "\n",
    "    line = x.split('\\t')\n",
    "    if len(line) >1:\n",
    "        if line[1] == '<s> AND BENNI\\n':\n",
    "            print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
