{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "'''\n",
    "import sys\n",
    "sys.path.append('Classes')\n",
    "from arpy import *\n",
    "'''\n",
    "import arpa\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input - taken from set 1\n",
    "### prefix count\n",
    "### ngram count\n",
    "### n-1gram count\n",
    "### unigram count\n",
    "### pre-pre fix\n",
    "\n",
    "# Target - taken from set 2\n",
    "### $P_{MLE}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1060 6GB\n",
      "True\n",
      "Memory Usage:\n",
      "Allocated: 0.0 MB\n",
      "Cached:    0.0 MB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    #print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**2,1), 'MB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**2,1), 'MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set 1 dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32203379/32203379 [00:31<00:00, 1025549.36it/s]\n"
     ]
    }
   ],
   "source": [
    "file = '../../rsc/11_12_counts.txt'\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "\n",
    "ngram_dict1 = {}\n",
    "for x in tqdm(first_read, total=num_lines):\n",
    "    line = x.split('\\t')\n",
    "    r = int(line[-1])\n",
    "    ngram_dict1[line[0]] = r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set 2 dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28246110/28246110 [00:27<00:00, 1037756.01it/s]\n"
     ]
    }
   ],
   "source": [
    "file = '../../rsc/13_14_counts.txt'\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "\n",
    "ngram_dict2 = {}\n",
    "for x in tqdm(first_read, total=num_lines):\n",
    "    line = x.split('\\t')\n",
    "    r = int(line[-1])\n",
    "    ngram_dict2[line[0]] = r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get tensor length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32203379/32203379 [00:33<00:00, 958278.47it/s]\n",
      "100%|██████████| 28246110/28246110 [00:29<00:00, 950612.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4793918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file = '../../rsc/11_12_counts.txt'\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "num_trigrams = 0\n",
    "\n",
    "for x in tqdm(first_read, total=num_lines, position = 0, leave = True):\n",
    "    line = x.split('\\t')\n",
    "    r = int(line[-1])\n",
    "    ngram = line[0].split(' ')\n",
    "    tuple_size = len(ngram)\n",
    "\n",
    "    if tuple_size == 3 and r < 8 and r!= 1:\n",
    "        num_trigrams += 1\n",
    "        \n",
    "        try:\n",
    "            #output - from set 1 = trigram count/ prefix\n",
    "            temp = ngram_dict2[line[0]] / ngram_dict2[ngram[0] + ' ' + ngram[1]]\n",
    "        except:\n",
    "            num_trigrams -= 1\n",
    "            \n",
    "##########repeat for reverse set#########################\n",
    "file = '../../rsc/13_14_counts.txt'\n",
    "second_read = open(file ,'r')\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "\n",
    "for x in tqdm(second_read, total=num_lines, position = 0, leave = True):\n",
    "    line = x.split('\\t')\n",
    "    r = int(line[-1])\n",
    "    ngram = line[0].split(' ')\n",
    "    tuple_size = len(ngram)\n",
    "\n",
    "    if tuple_size == 3 and r < 8 and r!= 1:\n",
    "        num_trigrams += 1\n",
    "        \n",
    "        try:\n",
    "            #output - from set 1 = trigram count/ prefix\n",
    "            temp = ngram_dict1[line[0]] / ngram_dict1[ngram[0] + ' ' + ngram[1]]\n",
    "        except:\n",
    "            num_trigrams -= 1\n",
    "\n",
    "\n",
    "print(num_trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instantiate tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#inputs = data[0].to(device)\n",
    "\n",
    "inputs = torch.zeros(5,num_trigrams, dtype=torch.float, device = device)\n",
    "print(inputs)\n",
    "outputs = torch.zeros(1,num_trigrams, dtype=torch.float, device = device)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fill tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32203379/32203379 [08:04<00:00, 66451.50it/s] \n",
      "100%|██████████| 28246110/28246110 [07:51<00:00, 59943.94it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4793918\n",
      "5331184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file = '../../rsc/11_12_counts.txt'\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "count = 0\n",
    "err = 0\n",
    "\n",
    "for x in tqdm(first_read, total=num_lines, position = 0, leave = True):\n",
    "    line = x.split('\\t')\n",
    "    r = int(line[-1])\n",
    "    ngram = line[0].split(' ')\n",
    "    tuple_size = len(ngram)\n",
    "    \n",
    "    if tuple_size == 3 and r < 8 and r!= 1:\n",
    "       \n",
    "        try:\n",
    "            #output - from set 2 = trigram count/ prefix\n",
    "            outputs[0][count] = ngram_dict2[line[0]] / ngram_dict2[ngram[0] + ' ' + ngram[1]]\n",
    "            \n",
    "            #input - from set 1\n",
    "            inputs[0][count] = ngram_dict1[ngram[0] + ' ' + ngram[1]]  #prefix count\n",
    "            inputs[1][count] = ngram_dict1[line[0]]                    #trigram count\n",
    "            inputs[2][count] = ngram_dict1[ngram[1] + ' ' + ngram[2]]  #backoff bigram count\n",
    "            inputs[3][count] = ngram_dict1[ngram[2]]                   #unigram count\n",
    "            inputs[4][count] = ngram_dict1[ngram[0]]                   #pre-pre fix\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        except:\n",
    "            err += 1\n",
    "            \n",
    "        \n",
    "\n",
    "#######################now swap around sets and repeat#######################################\n",
    "file = '../../rsc/13_14_counts.txt'\n",
    "second_read = open(file ,'r')\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "\n",
    "\n",
    "for x in tqdm(second_read, total=num_lines, position = 0, leave = True):\n",
    "    line = x.split('\\t')\n",
    "    r = int(line[-1])\n",
    "    ngram = line[0].split(' ')\n",
    "    tuple_size = len(ngram)\n",
    "    \n",
    "    if tuple_size == 3 and r < 8 and r!= 1:     \n",
    "        \n",
    "        try:\n",
    "            #output - from set 1 = trigram count/ prefix\n",
    "            outputs[0][count] = ngram_dict1[line[0]] / ngram_dict1[ngram[0] + ' ' + ngram[1]]\n",
    "            \n",
    "            #input - from set 2\n",
    "            inputs[0][count] = ngram_dict2[ngram[0] + ' ' + ngram[1]]  #prefix count\n",
    "            inputs[1][count] = ngram_dict2[line[0]]                    #trigram count\n",
    "            inputs[2][count] = ngram_dict2[ngram[1] + ' ' + ngram[2]]  #backoff bigram count\n",
    "            inputs[3][count] = ngram_dict2[ngram[2]]                   #unigram count\n",
    "            inputs[4][count] = ngram_dict2[ngram[0]]                   #pre-pre fix\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        except:\n",
    "            err += 1\n",
    "            \n",
    "        \n",
    "print(count)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6000e+01, 4.9000e+01, 4.9000e+01,  ..., 2.2000e+01, 4.2500e+02,\n",
      "         4.2500e+02],\n",
      "        [2.0000e+00, 4.0000e+00, 2.0000e+00,  ..., 3.0000e+00, 2.0000e+00,\n",
      "         5.0000e+00],\n",
      "        [3.8470e+03, 1.6500e+02, 1.3400e+02,  ..., 3.8400e+02, 3.0000e+00,\n",
      "         4.8900e+02],\n",
      "        [1.3060e+06, 2.0879e+04, 1.3656e+04,  ..., 8.9540e+03, 3.7470e+03,\n",
      "         1.3817e+04],\n",
      "        [8.0870e+03, 8.0870e+03, 8.0870e+03,  ..., 8.0870e+03, 1.3060e+06,\n",
      "         1.3060e+06]], device='cuda:0')\n",
      "tensor([[0.1538, 0.0667, 0.0667,  ..., 0.1429, 0.0118, 0.0118]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.0000e+00, 6.0000e+00, 3.0000e+00,  ..., 4.0000e+00, 5.0000e+00,\n",
      "         5.0000e+00],\n",
      "        [2.0000e+00, 2.0000e+00, 3.0000e+00,  ..., 3.0000e+00, 3.0000e+00,\n",
      "         2.0000e+00],\n",
      "        [3.3570e+03, 5.4990e+03, 8.7100e+02,  ..., 1.5363e+04, 3.2000e+01,\n",
      "         2.0000e+00],\n",
      "        [1.2480e+05, 1.6983e+06, 4.6025e+04,  ..., 3.0418e+06, 2.2400e+04,\n",
      "         1.4920e+03],\n",
      "        [4.9700e+02, 4.9700e+02, 4.9700e+02,  ..., 1.0950e+03, 1.8000e+01,\n",
      "         5.0000e+00]], device='cuda:0')\n",
      "tensor([[1.0000, 0.1667, 1.0000,  ..., 0.6000, 1.0000, 0.1429]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(inputs, '../../pickles/50-50_5input_' + str(num_trigrams))\n",
    "torch.save(outputs, '../../pickles/50-50_output_' + str(num_trigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
