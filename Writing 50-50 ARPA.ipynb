{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "'''\n",
    "import sys\n",
    "sys.path.append('Classes')\n",
    "from arpy import *\n",
    "'''\n",
    "import arpa\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prep cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1060 6GB\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15718800/15718800 [00:15<00:00, 1043511.07it/s]\n"
     ]
    }
   ],
   "source": [
    "file = '../../rsc/dev_set/dev_counts.txt'\n",
    "#file = '../../rsc/13_14_counts.txt'\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "\n",
    "ngram_dict = {}\n",
    "for x in tqdm(first_read, total=num_lines, position=0, leave=True):\n",
    "    line = x.split('\\t')\n",
    "    r = int(line[-1])\n",
    "    ngram_dict[line[0]] = r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Prep NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=5, out_features=5, bias=True)\n",
       "  (fc2): Linear(in_features=5, out_features=5, bias=True)\n",
       "  (fc3): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 5)\n",
    "        self.fc2 = nn.Linear(5, 5)\n",
    "        self.fc3 = nn.Linear(5, 1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x)) \n",
    "        x = torch.sigmoid(self.fc3(x)) \n",
    "        return x\n",
    "    \n",
    "net = Net().cuda()\n",
    "net.load_state_dict(torch.load('NN saves/50-50_5inputs'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 7943.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['discount', '2', '0.496574\\n']\n",
      "['discount', '3', '0.643644\\n']\n",
      "['discount', '4', '0.669976\\n']\n",
      "['discount', '5', '0.773884\\n']\n",
      "['discount', '6', '0.797639\\n']\n",
      "['discount', '7', '0.842846\\n']\n",
      "[0.       0.       0.496574 0.643644 0.669976 0.773884 0.797639 0.842846]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file = '../../rsc/dev_set/gt3dc_dev.txt'\n",
    "#file = '../../rsc/dc_factors.txt'\n",
    "first_read = open(file ,'r')\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "first_read.readline()\n",
    "first_read.readline()\n",
    "first_read.readline()\n",
    "i = 2\n",
    "dcf = np.zeros(8)\n",
    "\n",
    "for x in tqdm(first_read, total=6, position=0, leave=True):\n",
    "    line = x.split(' ')\n",
    "    print(line)\n",
    "    dcf[i] = float(line[2])\n",
    "    i += 1\n",
    "    \n",
    "print(dcf)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Write ARPA\n",
    "## NN with 5 inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7123624/7123624 [24:03<00:00, 4934.60it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE estimates exceeded: 7.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file = '../../rsc/dev_set/smoothedLM_dev.arpa'\n",
    "#file = '../../rsc/smoothedLM.arpa'\n",
    "first_read = open(file ,'r')\n",
    "new_file = open(\"../../rsc/temp.arpa\",\"w+\")\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "current_ngram_len = 0\n",
    "TH_exceeded = 0\n",
    "count = 0\n",
    "nn_input = torch.zeros(1, 5, dtype = torch.float, device = device)\n",
    "\n",
    "\n",
    "for x in tqdm(first_read, total=num_lines, position=0, leave=True):\n",
    "    if x == '\\\\end\\\\\\n':\n",
    "        current_ngram_len = -1\n",
    "        new_file.write(x)\n",
    "    elif x == '\\n':\n",
    "        new_file.write(x)\n",
    "    elif current_ngram_len < 3:\n",
    "        new_file.write(x)\n",
    "    elif current_ngram_len == 3:\n",
    "        #evaluate count\n",
    "        line = x.split('\\t')\n",
    "        r = ngram_dict[line[1][:-1]]\n",
    "        if r == 1 :\n",
    "            print('oops')\n",
    "\n",
    "        if r > 1 and r < 8: #only smooth values for r < 8\n",
    "            prob = 10**float(line[0])\n",
    "            ngram = line[1].split(' ')\n",
    "            ngram[2] = ngram[2][:-1]\n",
    "            count += 1\n",
    "            \n",
    "            ######setup nn input#######\n",
    "            nn_input[0][0] = ngram_dict[ngram[0] + ' ' + ngram[1]]  #prefix count\n",
    "            nn_input[0][1] = ngram_dict[line[1][:-1]]               #trigram count\n",
    "            nn_input[0][2] = ngram_dict[ngram[1] + ' ' + ngram[2]]  #backoff bigram count\n",
    "            nn_input[0][3] = ngram_dict[ngram[2]]                   #unigram count\n",
    "            nn_input[0][4] = ngram_dict[ngram[0]]                   #pre-prefix count\n",
    "            \n",
    "            nn_input = 1/nn_input #normalise\n",
    "\n",
    "            MLE = nn_input[0][0]/nn_input[0][1] #get threshold value\n",
    "            nn_prob  = net(nn_input)            #get NN value\n",
    "\n",
    "            if nn_prob > (MLE):           #check threshold\n",
    "                TH_exceeded += 1\n",
    "                nn_prob = MLE\n",
    "                \n",
    "            #multiply with GT dc factor\n",
    "            nn_prob = nn_prob * dcf[r]\n",
    "            '''\n",
    "            nn_prob = ngram_dict[line[1][:-1]]  / ngram_dict[ngram[0] + ' ' + ngram[1]]\n",
    "            nn_prob = nn_prob * dcf[r]\n",
    "            '''\n",
    "            \n",
    "            logbase = math.log(nn_prob, 10)\n",
    "            new_file.write('{:.7f}\\t{}\\n'.format(logbase, line[1][:-1]))\n",
    "        else:\n",
    "            new_file.write(x)\n",
    "            \n",
    "    if x == '\\\\1-grams:\\n':\n",
    "        current_ngram_len = 1\n",
    "    if x == '\\\\2-grams:\\n':\n",
    "        current_ngram_len = 2\n",
    "    if x == '\\\\3-grams:\\n':\n",
    "        current_ngram_len = 3\n",
    "        \n",
    "new_file.close()\n",
    "print('MLE estimates exceeded: {:.2f}%'.format((TH_exceeded/count)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4829103\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# copy bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12421255/12421255 [00:36<00:00, 341903.72it/s]\n"
     ]
    }
   ],
   "source": [
    "file1, file2 = '../../rsc/temp.arpa', '../../rsc/smoothedLM.arpa'\n",
    "first_read, second_read = open(file1 ,'r'), open(file2 , 'r')\n",
    "new_file = open('../../rsc/output_LM.arpa',\"w+\")\n",
    "num_lines = sum(1 for line in open(file1,'r'))\n",
    "\n",
    "for x in tqdm(range(0,num_lines), position=0, leave=True):\n",
    "    line1, line2 = first_read.readline().split('\\t') , second_read.readline().split('\\t')\n",
    "    \n",
    "    if line1[0][0] != '\\\\' and line1[0] !='\\n' and line1[0][0] != 'n':        \n",
    "        ngram = line1[1].split(' ')\n",
    "        r = len(ngram)\n",
    "        \n",
    "        if r == 2: #read until bigrams are reached in ARPA file\n",
    "            for y in line2: #write smoothed bigram value\n",
    "                new_file.write(y)\n",
    "                if y[-1:] != '\\n':\n",
    "                    new_file.write('\\t')\n",
    "        else:\n",
    "            for y in line1: #write values for unigrams and trigrams\n",
    "                new_file.write(y)\n",
    "                if y[-1:] != '\\n':\n",
    "                    new_file.write('\\t')\n",
    "    else:\n",
    "        for y in line1:\n",
    "            new_file.write(y)\n",
    "        \n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
