{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "'''\n",
    "import sys\n",
    "sys.path.append('Classes')\n",
    "from arpy import *\n",
    "'''\n",
    "import arpa\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input:\n",
    "### prefix count\n",
    "### ngram count\n",
    "### n-1gram count\n",
    "### unigram count\n",
    "\n",
    "# Target \n",
    "### Pgt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read counts into dictionary first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45918515/45918515 [00:46<00:00, 979553.46it/s] \n"
     ]
    }
   ],
   "source": [
    "file = '../../rsc/train_counts.txt'\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "\n",
    "ngram_dict = {}\n",
    "for x in tqdm(first_read, total=num_lines):\n",
    "    line = x.split('\\t')\n",
    "    r = int(line[-1])\n",
    "    ngram_dict[line[0]] = r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    #print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**2,1), 'MB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**2,1), 'MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trigram Counts to tensor\n",
    "### i. e. amount of trigrams to be smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45918515/45918515 [00:43<00:00, 1062493.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8813319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file = '../../rsc/train_counts.txt'\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "num_trigrams = 0\n",
    "\n",
    "for x in tqdm(first_read, total=num_lines):\n",
    "    line = x.split('\\t')\n",
    "    r = int(line[-1])\n",
    "    ngram = line[0].split(' ')\n",
    "    tuple_size = len(ngram)\n",
    "\n",
    "    if tuple_size == 3 and r < 8 and r!= 1:\n",
    "        num_trigrams += 1\n",
    "        \n",
    "print(num_trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## instantiate input tensors on gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#inputs = data[0].to(device)\n",
    "inputs = torch.zeros(4,num_trigrams, dtype=torch.float, device = device)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ngram_dict[\"\\' A P.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill input tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../../rsc/train_counts.txt'\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "count = 0\n",
    "\n",
    "for x in tqdm(first_read, total=num_lines):\n",
    "    line = x.split('\\t')\n",
    "    r = int(line[-1])\n",
    "    ngram = line[0].split(' ')\n",
    "    tuple_size = len(ngram)\n",
    "    \n",
    "    if tuple_size == 3 and r < 8 and r!= 1:\n",
    "        inputs[0][count] = ngram_dict[ngram[0] + ' ' + ngram[1]]  #prefix count\n",
    "        inputs[1][count] = ngram_dict[line[0]]                    #trigram count\n",
    "        inputs[2][count] = ngram_dict[ngram[1] + ' ' + ngram[2]]  #backoff bigram count\n",
    "        inputs[3][count] = ngram_dict[ngram[2]]                   #unigram count\n",
    "        \n",
    "        '''\n",
    "        if inputs[1][count]/inputs[0][count] == 1:\n",
    "            print(ngram)\n",
    "        count += 1\n",
    "        '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving input tensors using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(inputs, '../../pickles/train_input_' + str(num_trigrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!! reset kernel to prevent mem crash !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trigram Counts to tensor again\n",
    "### i. e. amount of trigrams to be smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45918515/45918515 [00:42<00:00, 1080963.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8813319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file = '../../rsc/train_counts.txt'\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "num_trigrams = 0\n",
    "\n",
    "for x in tqdm(first_read, total=num_lines,position = 0 , leave = True):\n",
    "    line = x.split('\\t')\n",
    "    r = int(line[-1])\n",
    "    ngram = line[0].split(' ')\n",
    "    tuple_size = len(ngram)\n",
    "\n",
    "    if tuple_size == 3 and r < 8 and r!= 1:\n",
    "        num_trigrams += 1\n",
    "        \n",
    "print(num_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1060 6GB\n",
      "True\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "Memory Usage:\n",
      "Allocated: 34.0 MB\n",
      "Cached:    36.0 MB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "outputs = torch.zeros(1,num_trigrams, dtype=torch.float, device = device)\n",
    "print(outputs)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    #print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**2,1), 'MB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**2,1), 'MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill output tensors\n",
    "### load in smoothed arpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = arpa.loadf('../../rsc/smoothedLM.arpa')\n",
    "#ABOUT CERTAIN AREAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pgt(BENNI | <s>, AND) = 1.228550463195926e-05\n",
      "Pgt('HO' | '<s>', 'GUNG') = 0.6563238707493194\n"
     ]
    }
   ],
   "source": [
    "#examples\n",
    "print('Pgt(BENNI | <s>, AND) = ' + str(lm[0].p(\"<s> AND BENNI\")))\n",
    "print('Pgt(\\'HO\\' | \\'<s>\\', \\'GUNG\\') = ' + str(lm[0].p(\"<s> GUNG HO\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get smoothed probs for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45918515/45918515 [07:43<00:00, 99167.15it/s] \n"
     ]
    }
   ],
   "source": [
    "file = '../../rsc/train_counts.txt'\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "count = 0\n",
    "for x in tqdm(first_read, total=num_lines, position = 0, leave = True):\n",
    "    line = x.split('\\t')\n",
    "    r = int(line[-1])\n",
    "    ngram = line[0].split(' ')\n",
    "    tuple_size = len(ngram)\n",
    "    \n",
    "    if tuple_size == 3 and r < 8 and r!= 1:\n",
    "        #Pgt\n",
    "        outputs[0][count] = lm[0].p(line[0])\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2648, 0.2461, 0.2461,  ..., 0.2883, 0.0623, 0.1158]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving output tensors using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(outputs, '../../pickles/train_output_' + str(num_trigrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving on to next Notebook:\n",
    "## Training NN on counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
