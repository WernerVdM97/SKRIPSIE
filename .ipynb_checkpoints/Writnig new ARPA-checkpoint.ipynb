{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "'''\n",
    "import sys\n",
    "sys.path.append('Classes')\n",
    "from arpy import *\n",
    "'''\n",
    "import arpa\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prep cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1060 6GB\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45918515/45918515 [00:47<00:00, 971822.91it/s] \n"
     ]
    }
   ],
   "source": [
    "file = '../../rsc/train_counts.txt'\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "\n",
    "ngram_dict = {}\n",
    "for x in tqdm(first_read, total=num_lines, position=0, leave=True):\n",
    "    line = x.split('\\t')\n",
    "    r = int(line[-1])\n",
    "    ngram_dict[line[0]] = r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Prep NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  (fc3): Linear(in_features=4, out_features=3, bias=True)\n",
       "  (fc4): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 4)\n",
    "        #self.fc2 = nn.Linear(4, 4)\n",
    "        self.fc3 = nn.Linear(4, 3)\n",
    "        self.fc4 = nn.Linear(3, 1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        #x = torch.sigmoid(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x)) \n",
    "        x = torch.sigmoid(self.fc4(x)) \n",
    "        return x\n",
    "'''\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 3)\n",
    "        #self.fc2 = nn.Linear(4, 4)\n",
    "        self.fc3 = nn.Linear(3, 3)\n",
    "        self.fc4 = nn.Linear(3, 1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        #x = torch.sigmoid(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x)) \n",
    "        x = torch.sigmoid(self.fc4(x)) \n",
    "        return x\n",
    "'''\n",
    "net = Net().cuda()\n",
    "net.load_state_dict(torch.load('NN saves/temp_50-50'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Write ARPA\n",
    "## NN with 4 inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../../rsc/unsmoothedLM.arpa'\n",
    "first_read = open(file ,'r')\n",
    "new_file = open(\"../../rsc/output_LM.arpa\",\"w+\")\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "current_ngram_len = 0\n",
    "TH_exceeded = 0\n",
    "count = 0\n",
    "nn_input = torch.zeros(1, 4, dtype = torch.float, device = device)\n",
    "\n",
    "for x in tqdm(first_read, total=num_lines, position=0, leave=True):\n",
    "    if x == '\\\\end\\\\\\n':\n",
    "        current_ngram_len = -1\n",
    "        new_file.write(x)\n",
    "    elif x == '\\n':\n",
    "        new_file.write(x)\n",
    "    elif current_ngram_len < 3:  \n",
    "        new_file.write(x)\n",
    "    elif current_ngram_len == 3: #trigrams\n",
    "        line = x.split('\\t')\n",
    "        r = ngram_dict[line[1][:-1]] #get ngram occurence\n",
    "\n",
    "        if r > 1 and r < 8: #only smooth applicable trigrams\n",
    "            prob = 10**float(line[0])  #retrieve ngram prob from ARPA\n",
    "            ngram = line[1].split(' ') #retrieve ngram\n",
    "            ngram[2] = ngram[2][:-1]   \n",
    "            count += 1\n",
    "            \n",
    "            ######setup nn input#######\n",
    "            nn_input[0][0] = ngram_dict[ngram[0] + ' ' + ngram[1]]  #prefix count\n",
    "            nn_input[0][1] = ngram_dict[line[1][:-1]]               #trigram count\n",
    "            nn_input[0][2] = ngram_dict[ngram[1] + ' ' + ngram[2]]  #backoff bigram count\n",
    "            nn_input[0][3] = ngram_dict[ngram[2]]                   #unigram count\n",
    "            nn_input = 1/nn_input #normalise\n",
    "\n",
    "            MLE = nn_input[0][0]/nn_input[0][1]  #get Threshold\n",
    "            smoothed_prob  = net(nn_input)       #get NN value\n",
    "\n",
    "            if smoothed_prob > (MLE): #evaluate threshold\n",
    "                TH_exceeded += 1\n",
    "                new_file.write(x) #write GT value\n",
    "                \n",
    "                #write MLE value\n",
    "                smoothed_prob = MLE\n",
    "                logbase = math.log(smoothed_prob, 10)\n",
    "                new_file.write('{:.7f}\\t{}\\n'.format(logbase, line[1][:-1]))\n",
    "                \n",
    "            else:\n",
    "                logbase = math.log(smoothed_prob, 10)\n",
    "                new_file.write('{:.7f}\\t{}\\n'.format(logbase, line[1][:-1]))\n",
    "        else:\n",
    "            new_file.write(x)\n",
    "            \n",
    "    if x == '\\\\1-grams:\\n':\n",
    "        current_ngram_len = 1\n",
    "    if x == '\\\\2-grams:\\n':\n",
    "        current_ngram_len = 2\n",
    "    if x == '\\\\3-grams:\\n':\n",
    "        current_ngram_len = 3\n",
    "        \n",
    "new_file.close()\n",
    "print('MLE estimates exceeded: {:.2f}%'.format((TH_exceeded/count)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inject GT smoothed bigrams into NN LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, file2 = '../../rsc/nnLM.arpa', '../../rsc/smoothedLM.arpa'\n",
    "first_read, second_read = open(file1 ,'r'), open(file2 , 'r')\n",
    "new_file = open('../../rsc/output_LM.arpa',\"w+\")\n",
    "num_lines = sum(1 for line in open(file1,'r'))\n",
    "\n",
    "for x in tqdm(range(0,num_lines), position=0, leave=True):\n",
    "    line1, line2 = first_read.readline().split('\\t') , second_read.readline().split('\\t')\n",
    "    \n",
    "    if line1[0][0] != '\\\\' and line1[0] !='\\n' and line1[0][0] != 'n':        \n",
    "        ngram = line1[1].split(' ')\n",
    "        r = len(ngram)\n",
    "        \n",
    "        if r == 2: #read until bigrams are reached in ARPA file\n",
    "            for y in line2: #write smoothed bigram value\n",
    "                new_file.write(y)\n",
    "                if y[-1:] != '\\n':\n",
    "                    new_file.write('\\t')\n",
    "        else:\n",
    "            for y in line1: #write values for unigrams and trigrams\n",
    "                new_file.write(y)\n",
    "                if y[-1:] != '\\n':\n",
    "                    new_file.write('\\t')\n",
    "    else:\n",
    "        for y in line1:\n",
    "            new_file.write(y)\n",
    "        \n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 10125136/19630106 [00:05<00:04, 2002186.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.727726\t<s> AND BENNI\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19630106/19630106 [00:10<00:00, 1962939.51it/s]\n"
     ]
    }
   ],
   "source": [
    "#start = time.time()\n",
    "#file = '../../temp/test/12-14_bigrams_discounted.arpa'\n",
    "file = '../../rsc/unsmoothedLM.arpa'\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "prob = 0\n",
    "tot_prob = 0\n",
    "prob2 = 0\n",
    "tot_prob2 = 0\n",
    "prob3 = 0\n",
    "tot_prob3 = 0\n",
    "\n",
    "\n",
    "for x in tqdm(first_read, total=num_lines, position=0, leave=True):\n",
    "\n",
    "    line = x.split('\\t')\n",
    "    if len(line) >1:\n",
    "        if line[1] == '<s> AND BENNI\\n':\n",
    "            print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hos, cheerss = 1 , 2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
