{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "'''\n",
    "import sys\n",
    "sys.path.append('Classes')\n",
    "from arpy import *\n",
    "'''\n",
    "import arpa\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prep cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1060 6GB\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9ad4d1de1b78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mngram_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "#start = time.time()\n",
    "#file = '../../rsc/train_counts.txt'\n",
    "file = '../../rsc/old/12_14counts.txt'\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "#print(num_lines)\n",
    "\n",
    "ngram_dict = {}\n",
    "for x in tqdm(first_read, total=num_lines, position=0, leave=True):\n",
    "    line = x.split('\\t')\n",
    "    r = int(line[-1])\n",
    "    ngram_dict[line[0]] = r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Prep NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 4)\n",
    "        #self.fc2 = nn.Linear(4, 4)\n",
    "        self.fc3 = nn.Linear(4, 3)\n",
    "        self.fc4 = nn.Linear(3, 1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        #x = torch.sigmoid(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x)) \n",
    "        x = torch.sigmoid(self.fc4(x)) \n",
    "        return x\n",
    "'''\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 3)\n",
    "        #self.fc2 = nn.Linear(4, 4)\n",
    "        self.fc3 = nn.Linear(3, 3)\n",
    "        self.fc4 = nn.Linear(3, 1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        #x = torch.sigmoid(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x)) \n",
    "        x = torch.sigmoid(self.fc4(x)) \n",
    "        return x\n",
    "\n",
    "net = Net().cuda()\n",
    "net.load_state_dict(torch.load('NN saves/temp'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Write ARPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 15396614/17067352 [43:48<10:12, 2726.84it/s]  "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f942f39fda57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;31m#print(r)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0merror\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mlogbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmoothed_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m#write\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 15396614/17067352 [44:03<10:12, 2726.84it/s]"
     ]
    }
   ],
   "source": [
    "#start = time.time()\n",
    "file = '../../temp/12-14o.arpa'\n",
    "#file = '../../temp/small.arpa'\n",
    "first_read = open(file ,'r')\n",
    "new_file = open(\"../../temp/test/nn_12-14.arpa\",\"w+\")\n",
    "#new_file = open('../../temp/nn_small.arpa' , 'w+')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "current_ngram_len = 0\n",
    "error = 0\n",
    "count = 0\n",
    "nn_input = torch.zeros(1, 4, dtype = torch.float, device = device)\n",
    "\n",
    "\n",
    "for x in tqdm(first_read, total=num_lines, position=0, leave=True):\n",
    "    if x == '\\\\end\\\\\\n':\n",
    "        current_ngram_len = -1\n",
    "        new_file.write(x)\n",
    "    elif x == '\\n':\n",
    "        new_file.write(x)\n",
    "    elif current_ngram_len < 3:\n",
    "        new_file.write(x)\n",
    "    elif current_ngram_len == 3:\n",
    "        #evaluate count\n",
    "        line = x.split('\\t')\n",
    "        r = ngram_dict[line[1][:-1]]\n",
    "        if r ==1 :\n",
    "            print('oops')\n",
    "\n",
    "        if r > 1 and r < 8: #only smooth values for r < 8\n",
    "            prob = 10**float(line[0])\n",
    "            ngram = line[1].split(' ')\n",
    "            ngram[2] = ngram[2][:-1]\n",
    "            count += 1\n",
    "            \n",
    "            ######setup nn input#######\n",
    "            nn_input[0][0] = ngram_dict[ngram[0] + ' ' + ngram[1]]  #prefix count\n",
    "            nn_input[0][1] = ngram_dict[line[1][:-1]]               #trigram count\n",
    "            nn_input[0][2] = ngram_dict[ngram[1] + ' ' + ngram[2]]  #backoff bigram count\n",
    "            nn_input[0][3] = ngram_dict[ngram[2]]                   #unigram count\n",
    "            nn_input = 1/nn_input\n",
    "\n",
    "            #p = pnn - bias value\n",
    "            smoothed_prob  = net(nn_input) - 0.01156371718934679\n",
    "            \n",
    "            if smoothed_prob > prob:\n",
    "                #print('error ' + str(smoothed_prob[0]) + ' vs ' + str(prob) )\n",
    "                #print(r)\n",
    "                error += 1\n",
    "                \n",
    "            #check for valid log(since bias can send it neg)\n",
    "            if smoothed_prob < 0:\n",
    "                smoothed_prob = \n",
    "            logbase = math.log(smoothed_prob, 10)\n",
    "\n",
    "            #write\n",
    "            new_file.write('{:.7f}\\t{}\\n'.format(logbase, line[1][:-1]))\n",
    "        else:\n",
    "            new_file.write(x)\n",
    "            \n",
    "    if x == '\\\\1-grams:\\n':\n",
    "        current_ngram_len = 1\n",
    "    if x == '\\\\2-grams:\\n':\n",
    "        current_ngram_len = 2\n",
    "    if x == '\\\\3-grams:\\n':\n",
    "        current_ngram_len = 3\n",
    "        \n",
    "new_file.close()\n",
    "print(error/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 8904103/16234238 [00:02<00:01, 3746134.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1983674\t~ L.\n",
      "\n",
      "-1.1983674\t~ M.\n",
      "\n",
      "-1.1983674\t~ THE\n",
      "\n",
      "-0.8973377\t~ ~\n",
      "\n",
      "-0.0222764\t~NINETY SIX\n",
      "\n",
      "\n",
      "\n",
      "-0.7803163\t' ' '\n",
      "\n",
      "-0.1026623\t<s> ' </s>\n",
      "\n",
      "-0.4522407\tA ' S.\n",
      "\n",
      "-0.06694679\tA. ' </s>\n",
      "\n",
      "-0.03778856\tAND ' </s>\n",
      "\n",
      "-0.3001802\tB. ' </s>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16234238/16234238 [00:04<00:00, 3633800.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n        if r > 1 and r < 8: #only smooth values for r < 8\\n            prob = 10**float(line[0])\\n            ngram = line[1].split(' ')\\n            ngram[2] = ngram[2][:-1]\\n            count += 1\\n            print('\\n' + x[:-1])\\n\\n            ######setup nn input#######\\n            nn_input[0][0] = ngram_dict[ngram[0] + ' ' + ngram[1]]  #prefix count\\n            print(nn_input[0][0])\\n            nn_input[0][1] = ngram_dict[line[1][:-1]]               #trigram count\\n            print(nn_input[0][1])\\n            nn_input[0][2] = ngram_dict[ngram[1] + ' ' + ngram[2]]  #backoff bigram count\\n            print(nn_input[0][2])\\n            nn_input[0][3] = ngram_dict[ngram[2]]                   #unigram count\\n            print(nn_input[0][3])\\n\\n            nn_input = 1/nn_input\\n\\n            print('\\n' + str(nn_input[0][0] / nn_input[0][1]))\\n            print(str(prob) +'\\n')\\n                  \\n            print(net(nn_input))\\n            #p = pnn - bias value\\n            smoothed_prob  = net(nn_input) - 0.01156371718934679\\n            print(smoothed_prob)\\n            logbase = math.log(smoothed_prob, 10)\\n            print(logbase)\\n\\n    count+=1\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start = time.time()\n",
    "file = '../../temp/test/nn_12-14_bigrams_discounted.arpa'\n",
    "#file = '../../temp/small.arpa'\n",
    "first_read = open(file ,'r')\n",
    "#new_file = open('../../temp/nn_small.arpa' , 'w+')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "current_ngram_len = 0\n",
    "error = 0\n",
    "count = 0\n",
    "nn_input = torch.zeros(1, 4, dtype = torch.float, device = device)\n",
    "\n",
    "\n",
    "for x in tqdm(first_read, total=num_lines, position=0, leave=True):\n",
    "    if count > 8218005 and count < 8218018:\n",
    "        #evaluate count\n",
    "        print(x)\n",
    "        #line = x.split('\\t')\n",
    "        #r = ngram_dict[line[1][:-1]]\n",
    "    count+=1\n",
    "'''\n",
    "        if r > 1 and r < 8: #only smooth values for r < 8\n",
    "            prob = 10**float(line[0])\n",
    "            ngram = line[1].split(' ')\n",
    "            ngram[2] = ngram[2][:-1]\n",
    "            count += 1\n",
    "            print('\\n' + x[:-1])\n",
    "\n",
    "            ######setup nn input#######\n",
    "            nn_input[0][0] = ngram_dict[ngram[0] + ' ' + ngram[1]]  #prefix count\n",
    "            print(nn_input[0][0])\n",
    "            nn_input[0][1] = ngram_dict[line[1][:-1]]               #trigram count\n",
    "            print(nn_input[0][1])\n",
    "            nn_input[0][2] = ngram_dict[ngram[1] + ' ' + ngram[2]]  #backoff bigram count\n",
    "            print(nn_input[0][2])\n",
    "            nn_input[0][3] = ngram_dict[ngram[2]]                   #unigram count\n",
    "            print(nn_input[0][3])\n",
    "\n",
    "            nn_input = 1/nn_input\n",
    "\n",
    "            print('\\n' + str(nn_input[0][0] / nn_input[0][1]))\n",
    "            print(str(prob) +'\\n')\n",
    "                  \n",
    "            print(net(nn_input))\n",
    "            #p = pnn - bias value\n",
    "            smoothed_prob  = net(nn_input) - 0.01156371718934679\n",
    "            print(smoothed_prob)\n",
    "            logbase = math.log(smoothed_prob, 10)\n",
    "            print(logbase)\n",
    "\n",
    "    count+=1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN with 3 inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../rsc/old/nn_12-14.arpa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-34e40c2fe58d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../../rsc/old/nn_12-14.arpa'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#file = '../../temp/small.arpa'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfirst_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnew_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../rsc/nn_LM_r!=1.arpa\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w+\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#new_file = open('../../temp/nn_small.arpa' , 'w+')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../rsc/old/nn_12-14.arpa'"
     ]
    }
   ],
   "source": [
    "#start = time.time()\n",
    "file = '../../rsc/old/nn_12-14.arpa'\n",
    "#file = '../../temp/small.arpa'\n",
    "first_read = open(file ,'r')\n",
    "new_file = open(\"../../rsc/nn_LM_r!=1.arpa\",\"w+\")\n",
    "#new_file = open('../../temp/nn_small.arpa' , 'w+')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "current_ngram_len = 0\n",
    "error = 0\n",
    "count = 0\n",
    "fuck = 0\n",
    "nn_input = torch.zeros(1, 3, dtype = torch.float, device = device)\n",
    "\n",
    "\n",
    "for x in tqdm(first_read, total=num_lines, position=0, leave=True):\n",
    "    if x == '\\\\end\\\\\\n':\n",
    "        current_ngram_len = -1\n",
    "        new_file.write(x)\n",
    "    elif x == '\\n':\n",
    "        new_file.write(x)\n",
    "    elif current_ngram_len < 2: #responsible for writing \\data\\ as well as \\1-grams:\n",
    "        new_file.write(x)\n",
    "    elif x == '\\\\3-grams:\\n':\n",
    "        new_file.write(x)\n",
    "    elif current_ngram_len == 2:#bigrams\n",
    "        #evaluate count\n",
    "        line = x.split('\\t')\n",
    "        \n",
    "        if len(line) == 2:\n",
    "            r = ngram_dict[line[1][:-1]]\n",
    "        elif len(line) == 3:\n",
    "            r = ngram_dict[line[1]]\n",
    "        \n",
    "            if r < 8 :\n",
    "                prob = 10**float(line[0])\n",
    "                logbase = math.log(prob*0.95, 10)\n",
    "\n",
    "                new_file.write('{:.7f}\\t{}\\t{:.8f}\\n'.format(logbase, line[1][:-1], -99))\n",
    "            else:\n",
    "                new_file.write('{:.7f}\\t{}\\t{:.8f}\\n'.format(float(line[0]), line[1][:-1], -99))\n",
    "\n",
    "    elif current_ngram_len == 3:#trigrams\n",
    "        #evaluate count\n",
    "        line = x.split('\\t')\n",
    "        r = ngram_dict[line[1][:-1]]\n",
    "\n",
    "        if r < 8 and r > 1: #only smooth values for r < 8, r = 1 does not exist for optim reasons\n",
    "            prob = 10**float(line[0])\n",
    "            ngram = line[1].split(' ')\n",
    "            ngram[2] = ngram[2][:-1]\n",
    "            count += 1\n",
    "            \n",
    "            ######setup nn input#######\n",
    "            MLE = ngram_dict[ngram[0] + ' ' + ngram[1]]/ngram_dict[line[1][:-1]]\n",
    "            MLE = 1/MLE\n",
    "            nn_input[0][0] = MLE                                    #prob\n",
    "            nn_input[0][1] = ngram_dict[ngram[1] + ' ' + ngram[2]]  #backoff bigram count\n",
    "            nn_input[0][2] = ngram_dict[ngram[2]]                   #unigram count\n",
    "            nn_input = 1/nn_input #corrects MLE\n",
    "            MLE = 1/MLE\n",
    "\n",
    "            #p = pnn - bias value\n",
    "            smoothed_prob  = net(nn_input) -0.00195\n",
    "            \n",
    "            if smoothed_prob > prob:\n",
    "                #print('error ' + str(smoothed_prob[0]) + ' vs ' + str(prob) )\n",
    "                #print(r)\n",
    "                error += 1\n",
    "                \n",
    "            #check for valid log(since bias can send it neg)\n",
    "            if smoothed_prob > MLE:\n",
    "                fuck +=1\n",
    "            else:\n",
    "\n",
    "                logbase = math.log(smoothed_prob, 10)\n",
    "\n",
    "            #write\n",
    "            new_file.write('{:.7f}\\t{}\\n'.format(logbase, line[1][:-1]))\n",
    "            \n",
    "    if x == '\\\\1-grams:\\n':\n",
    "        current_ngram_len = 1\n",
    "        new_file.write(x)\n",
    "    if x == '\\\\2-grams:\\n':\n",
    "        current_ngram_len = 2\n",
    "        new_file.write(x)\n",
    "    if x == '\\\\3-grams:\\n':\n",
    "        current_ngram_len = 3\n",
    "        \n",
    "new_file.close()\n",
    "print(error/count)\n",
    "print('fucks: ' + str(fuck))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45919088/45919088 [00:42<00:00, 1069400.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000004310510426\n",
      "0.0013748771910746349\n",
      "0.051931086925313126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#start = time.time()\n",
    "#file = '../../temp/test/12-14_bigrams_discounted.arpa'\n",
    "file = '../../rsc/unsmoothed_LM.arpa'\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "prob = 0\n",
    "tot_prob = 0\n",
    "prob2 = 0\n",
    "tot_prob2 = 0\n",
    "prob3 = 0\n",
    "tot_prob3 = 0\n",
    "\n",
    "\n",
    "for x in tqdm(first_read, total=num_lines, position=0, leave=True):\n",
    "\n",
    "    line = x.split('\\t')\n",
    "    if len(line) == 2:\n",
    "        ngram = line[1].split(' ')\n",
    "        \n",
    "        if len(ngram) == 1:\n",
    "            prob3 = 10**float(line[0])\n",
    "            tot_prob3 += prob3\n",
    "        \n",
    "        if len(ngram) == 2:\n",
    "            unigram = ngram[0]\n",
    "            #print(ngram)\n",
    "            if unigram == 'JUST':\n",
    "                #print(x)\n",
    "                prob2 = 10**float(line[0])\n",
    "                tot_prob2 += prob2\n",
    "        \n",
    "        if len(ngram) == 3:\n",
    "            prefix = ngram[0] + ' ' + ngram[1]\n",
    "            if prefix == 'A JUST':\n",
    "                prob = 10**float(line[0])\n",
    "                tot_prob += prob\n",
    "                #print(x)\n",
    "        \n",
    "print(tot_prob)\n",
    "print(tot_prob2)\n",
    "print(tot_prob3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
