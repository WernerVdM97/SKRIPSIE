{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "'''\n",
    "import sys\n",
    "sys.path.append('Classes')\n",
    "from arpy import *\n",
    "'''\n",
    "import arpa\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import json\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input:\n",
    "### ngram count\n",
    "### n-1gram count\n",
    "### unigram count\n",
    "### prefix count\n",
    "\n",
    "# Target \n",
    "### Pgt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# processing ngram counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "file = open('../../2000-2014_ngram_counts.txt','r')\n",
    "\n",
    "counts = np.zeros(8)\n",
    "\n",
    "for x in file:\n",
    "    line = x.split('\\t')\n",
    "    r = line[1].split('\\n')\n",
    "    if (int(r[0]) < 9):\n",
    "        counts[int(r[0])-1] += 1\n",
    "        \n",
    "print('amount of ngrams occuring r times:')\n",
    "print(counts)\n",
    "end = time.time()\n",
    "print('time:' + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(counts[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "file = open('../../2000-2014_ngram_counts.txt','r')\n",
    "\n",
    "totals = np.zeros(3)\n",
    "ngrams = 0\n",
    "\n",
    "for x in file:\n",
    "    line = x.split('\\t')\n",
    "    tuple_size = len(line[0].split(' '))\n",
    "\n",
    "    r = line[1].split('\\n')\n",
    "    totals[tuple_size-1] = totals[tuple_size-1] + int(r[0])\n",
    "\n",
    "    ngrams += 1\n",
    "\n",
    "print('sum of ngrams counts:')\n",
    "print(totals)\n",
    "print('total unique ngrams:')\n",
    "print(ngrams)\n",
    "end = time.time()\n",
    "print('time: ' + str(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing on smaller sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "file = open('../../GTBO_LM.lm','r')\n",
    "#file = open('../../lm','r')\n",
    "\n",
    "\n",
    "total = 0\n",
    "ngrams = 0\n",
    "\n",
    "for x in range(5):\n",
    "    file.readline()\n",
    "\n",
    "for x in file:\n",
    "    line = x.split('\\t')\n",
    "    if line[0] != '\\n':\n",
    "        if line[0] != '':\n",
    "            if line[0][0] != '\\\\':\n",
    "                #log = float(line[0])\n",
    "                #total = total + 10**log\n",
    "                #print('\\ntotal: ' + str(total))\n",
    "                #print(10**log)\n",
    "                ngrams+=1\n",
    "    \n",
    "print(ngrams)\n",
    "end = time.time()\n",
    "print('time: ' + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "file = open('../../count.txt','r')\n",
    "\n",
    "totals = np.zeros(3)\n",
    "ngrams = 0\n",
    "\n",
    "for x in file:\n",
    "    line = x.split('\\t')\n",
    "    tuple_size = len(line[0].split(' '))\n",
    "    r = line[-1].split('\\n')\n",
    "    totals[tuple_size-1] = totals[tuple_size-1] + int(r[0])\n",
    "    ngrams += 1\n",
    "    \n",
    "print(totals)\n",
    "print(ngrams)\n",
    "end = time.time()\n",
    "print('time: ' + str(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python arpa file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = arpa.loadf('../../round1/practiseLM.arpa')\n",
    "#ABOUT CERTAIN AREAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pgt calculated by srilm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pgt(' + str(lm[0].p(\"ABOUT CERTAIN AREAS\")) + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get discount factors from srilm output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtdc = open('../../round1/practise_gt_dc.txt','r')\n",
    "dc = np.zeros(7)\n",
    "\n",
    "gtdc.readline()\n",
    "gtdc.readline()\n",
    "\n",
    "for x in range(7):\n",
    "    line = gtdc.readline()\n",
    "    line = line.split(' ')[2].split('\\n')[0]\n",
    "    dc[x] = float(line)\n",
    "    \n",
    "print('discount factor for r = 1, 2, 3, 4, 5, 6, 7')\n",
    "print(dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prf - calculated by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "file = open('../../round1/2000counts.txt','r')\n",
    "\n",
    "trigram = 0\n",
    "bigrams = 0\n",
    "\n",
    "for x in file:\n",
    "    #line = file.readline()\n",
    "    #line = line.split('\\t')\n",
    "    line = x.split('\\t')\n",
    "    tuple_size = len(line[0].split(' '))\n",
    "    \n",
    "    ngram = line[0]\n",
    "    r = line[-1].split('\\n')[0]\n",
    "\n",
    "    if ngram == 'ABOUT CERTAIN AREAS':\n",
    "        trigram = r\n",
    "    if ngram == 'ABOUT CERTAIN':\n",
    "        bigram = r\n",
    "        \n",
    "    '''\n",
    "    print(ngram)\n",
    "    print('tuple size: ' + str(tuple_size))\n",
    "    print('count: ' + str(r))\n",
    "    '''\n",
    "\n",
    "print('trigram count: '+ trigram)\n",
    "print('bigram count: ' + bigram)\n",
    "prf = float(trigram)/float(bigram)\n",
    "print('Prf(' + str(prf) +')')\n",
    "\n",
    "end = time.time()\n",
    "print('time: ' + str(end-start))\n",
    "\n",
    "print('Pgt(' + str(prf*dc[int(trigram)-1]) + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB! Pgt = discountfactor(r) * Prf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find ngrams with r > 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "file = open('../../round1/2000counts.txt','r')\n",
    "\n",
    "trigram = 0\n",
    "bigrams = 0\n",
    "\n",
    "for x in range(1000):\n",
    "    line = file.readline()\n",
    "    line = line.split('\\t')\n",
    "    #line = x.split('\\t')\n",
    "    tuple_size = len(line[0].split(' '))\n",
    "    \n",
    "    ngram = line[0]\n",
    "    r = line[-1].split('\\n')[0]\n",
    "\n",
    "    if tuple_size == 3 and int(r) > 7:\n",
    "        print(ngram)\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    print(ngram)\n",
    "    print('tuple size: ' + str(tuple_size))\n",
    "    print('count: ' + str(r))\n",
    "    '''\n",
    "\n",
    "end = time.time()\n",
    "print('time: ' + str(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AS seen below, for r > Pgt = Prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pgt(' + str(lm[0].p(\".CO .ZA </s>\"))+ ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "file = open('../../round1/2000counts.txt','r')\n",
    "\n",
    "trigram = 0\n",
    "bigrams = 0\n",
    "\n",
    "for x in file:\n",
    "    #line = file.readline()\n",
    "    #line = line.split('\\t')\n",
    "    line = x.split('\\t')\n",
    "    tuple_size = len(line[0].split(' '))\n",
    "    \n",
    "    ngram = line[0]\n",
    "    r = line[-1].split('\\n')[0]\n",
    "\n",
    "    if ngram == '.CO .ZA </s>':\n",
    "        trigram = r\n",
    "    if ngram == '.CO .ZA':\n",
    "        bigram = r\n",
    "        \n",
    "    '''\n",
    "    print(ngram)\n",
    "    print('tuple size: ' + str(tuple_size))\n",
    "    print('count: ' + str(r))\n",
    "    '''\n",
    "\n",
    "print('trigram count: '+ trigram)\n",
    "print('bigram count: ' + bigram)\n",
    "prf = float(trigram)/float(bigram)\n",
    "print('Prf(' + str(prf) +')')\n",
    "\n",
    "end = time.time()\n",
    "print('time: ' + str(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read counts from file, VERY INEFFECTIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9672425\n"
     ]
    }
   ],
   "source": [
    "num_lines = sum(1 for line in open('../../round1/2000counts.txt','r'))\n",
    "#num_lines = sum(1 for line in open('../../count.txt','r'))\n",
    "\n",
    "print(num_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "file = '../../round1/2000counts.txt'\n",
    "#file = '../../count.txt'\n",
    "first_read = open(file ,'r')\n",
    "#second_read = open(file,'r')\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "for x in tqdm(first_read, total=num_lines):\n",
    "\n",
    "    line = x.split('\\t')\n",
    "    ngram = line[0].split(' ')\n",
    "    tuple_size = len(ngram)\n",
    "    r = int(line[-1])\n",
    "    \n",
    "    if tuple_size == 2:\n",
    "        prefix_count = r\n",
    "    \n",
    "    if tuple_size == 3 and r < 8:\n",
    "        #count += 1\n",
    "        #print('\\n' + ngram[0] +' '+ ngram[1]+' ' + ngram[2] + '\\t' + str(r))\n",
    "        #print(ngram[0] + ' '+ ngram[1] +'\\t' + str(prefix_count))\n",
    "        #print('\\n'+line[0])\n",
    "        #print(r)\n",
    "                \n",
    "        prefix = ngram[0] + ' ' + ngram[1]\n",
    "        bigram = ngram[1] + ' ' + ngram[2]\n",
    "                \n",
    "        \n",
    "        found_bigram = 0\n",
    "        found_unigram = 0\n",
    "        '''\n",
    "        for y in second_read:\n",
    "            \n",
    "            if y[0] == ngram[1][0]:\n",
    "                line2 = y.split('\\t')\n",
    "                tuple_size = len(line2[0].split(' '))\n",
    "                r_2 = int(line2[-1])\n",
    "\n",
    "                if bigram == line2[0]:\n",
    "                    found_bigram = 1\n",
    "                    #print(line2[0] + '\\t' + str(r_2))\n",
    "                    if found_unigram == 1:\n",
    "                        break\n",
    "                    \n",
    "            if y[0] == ngram[2][0]:\n",
    "                \n",
    "                line2 = y.split('\\t')\n",
    "                tuple_size = len(line2[0].split(' '))\n",
    "                r_2 = int(line2[-1])\n",
    "                \n",
    "                if ngram[2] == line2[0]:\n",
    "                    found_unigram = 1\n",
    "                    #print(line2[0] + '\\t' + str(r_2))\n",
    "                    if found_bigram == 1:\n",
    "                        break\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "print(count)\n",
    "end = time.time()\n",
    "print('time: ' + str(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read counts into dictionary first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15718800/15718800 [00:15<00:00, 1022245.59it/s]\n"
     ]
    }
   ],
   "source": [
    "#start = time.time()\n",
    "#file = '../../counts/2000counts.txt'\n",
    "#file = '../../counts/08_14counts.txt'\n",
    "#file = '../../counts/12_14counts.txt'\n",
    "file = '../../counts/dev_counts.txt'\n",
    "\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "#print(num_lines)\n",
    "\n",
    "ngram_dict = {}\n",
    "for x in tqdm(first_read, total=num_lines):\n",
    "    line = x.split('\\t')\n",
    "    r = int(line[-1])\n",
    "    ngram_dict[line[0]] = r\n",
    "\n",
    "#print(ngram_dict['H. I. V.'])\n",
    "#end = time.time()\n",
    "#print('time: ' + str(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get discount factors from srilm output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discount factor for r = 1, 2, 3, 4, 5, 6, 7\n",
      "[0.328853 0.496574 0.643644 0.669976 0.773884 0.797639 0.842846]\n"
     ]
    }
   ],
   "source": [
    "#gtdc = open('../../counts/gtdc_factors_08-14.txt','r')\n",
    "#gtdc = open('../../counts/gtdc_factors_2000.txt','r')\n",
    "#gtdc = open('../../counts/gt3dc_12-14.txt','r')\n",
    "gtdc = open('../../counts/gt3dc_dev.txt','r')\n",
    "\n",
    "dc = np.zeros(7)\n",
    "\n",
    "gtdc.readline()\n",
    "gtdc.readline()\n",
    "\n",
    "for x in range(7):\n",
    "    line = gtdc.readline()\n",
    "    line = line.split(' ')[2].split('\\n')[0]\n",
    "    dc[x] = float(line)\n",
    "    \n",
    "print('discount factor for r = 1, 2, 3, 4, 5, 6, 7')\n",
    "print(dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1060 6GB\n",
      "True\n",
      "Memory Usage:\n",
      "Allocated: 0.0 MB\n",
      "Cached:    0.0 MB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    #print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**2,1), 'MB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**2,1), 'MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Trigram Counts to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15718800/15718800 [00:14<00:00, 1056147.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2648573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#start = time.time()\n",
    "#file = '../../counts/08_14counts.txt'\n",
    "#file = '../../counts/2000counts.txt'\n",
    "#file = '../../counts/12_14counts.txt'\n",
    "file = '../../counts/dev_counts.txt'\n",
    "\n",
    "\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "#print(num_lines)\n",
    "num_trigrams = 0\n",
    "\n",
    "for x in tqdm(first_read, total=num_lines):\n",
    "    line = x.split('\\t')\n",
    "    r = int(line[-1])\n",
    "    ngram = line[0].split(' ')\n",
    "    tuple_size = len(ngram)\n",
    "\n",
    "    if tuple_size == 3 and r < 8 and r!= 1:\n",
    "        num_trigrams += 1\n",
    "        \n",
    "print(num_trigrams)\n",
    "end = time.time()\n",
    "#print('time: ' + str(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instantiate tensors on gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#inputs = data[0].to(device)\n",
    "inputs = torch.zeros(4,num_trigrams, dtype=torch.float, device = device)\n",
    "print(inputs)\n",
    "outputs = torch.zeros(1,num_trigrams, dtype=torch.float, device = device)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ngram_dict[\"\\' A P.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fill tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15718800/15718800 [09:11<00:00, 28486.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 552.9847664833069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#file = '../../counts/08_14counts.txt'\n",
    "#file = '../../counts/2000counts.txt'\n",
    "#file = '../../counts/12_14counts.txt'\n",
    "file = '../../counts/dev_counts.txt'\n",
    "\n",
    "\n",
    "first_read = open(file ,'r')\n",
    "\n",
    "num_lines = sum(1 for line in open(file,'r'))\n",
    "#print(num_lines)\n",
    "count = 0\n",
    "\n",
    "for x in tqdm(first_read, total=num_lines):\n",
    "    line = x.split('\\t')\n",
    "    r = int(line[-1])\n",
    "    ngram = line[0].split(' ')\n",
    "    tuple_size = len(ngram)\n",
    "    \n",
    "    if tuple_size == 3 and r < 8 and r!= 1:\n",
    "        inputs[0][count] = ngram_dict[ngram[0] + ' ' + ngram[1]]  #prefix count\n",
    "        inputs[1][count] = ngram_dict[line[0]]                    #trigram count\n",
    "        inputs[2][count] = ngram_dict[ngram[1] + ' ' + ngram[2]]  #backoff bigram count\n",
    "        inputs[3][count] = ngram_dict[ngram[2]]                   #unigram count\n",
    "        \n",
    "        #Pgt = Prf * dc_factor\n",
    "        outputs[0][count] = (inputs[1][count]/inputs[0][count]) * dc[r-1]    \n",
    "        count += 1\n",
    "        \n",
    "end = time.time()\n",
    "print('time: ' + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000e+00, 3.0000e+00, 2.0000e+00,  ..., 3.0000e+00, 5.0000e+00,\n",
      "         2.0000e+00],\n",
      "        [2.0000e+00, 2.0000e+00, 2.0000e+00,  ..., 2.0000e+00, 2.0000e+00,\n",
      "         2.0000e+00],\n",
      "        [3.2100e+02, 3.1100e+02, 2.1460e+03,  ..., 2.0000e+00, 5.0000e+00,\n",
      "         5.4752e+04],\n",
      "        [1.7450e+04, 2.4549e+04, 4.9295e+04,  ..., 7.0853e+05, 1.3115e+05,\n",
      "         1.5283e+06]], device='cuda:0')\n",
      "torch.Size([4, 2648573])\n",
      "tensor([[0.4966, 0.3310, 0.4966,  ..., 0.3310, 0.1986, 0.4966]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 2648573])\n"
     ]
    }
   ],
   "source": [
    "print(inputs)\n",
    "print(inputs.size())\n",
    "print(outputs)\n",
    "print(outputs.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving (and loading) tensors using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(inputs, '../../pickles/input_' + str(num_trigrams) +'_dev_file')\n",
    "torch.save(outputs, '../../pickles/output_' + str(num_trigrams) +'_dev_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
