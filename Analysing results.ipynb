{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 960M\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The FoLiA library pynlpl.formats.folia is being used but this version is now deprecated and is replaced by FoLiAPy (pip install folia), see https://github.com/proycon/foliapy. Please update your software if you are a developer, if you are an end-user you can safely ignore this message.\n",
      "/usr/local/lib/python3.6/dist-packages/pynlpl/lm/srilm.py:25: UserWarning: srilmcc module is not compiled\n",
      "  warnings.warn(\"srilmcc module is not compiled\")\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import arpa\n",
    "\n",
    "import pynlpl.lm.lm as pyn\n",
    "import pynlpl.lm.srilm as pynLM\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net2(\n",
       "  (fc1): Linear(in_features=5, out_features=5, bias=True)\n",
       "  (fc2): Linear(in_features=5, out_features=4, bias=True)\n",
       "  (fc3): Linear(in_features=4, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 4)\n",
    "        #self.fc2 = nn.Linear(4, 4)\n",
    "        self.fc3 = nn.Linear(4, 3)\n",
    "        self.fc4 = nn.Linear(3, 1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        #x = torch.sigmoid(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x)) \n",
    "        x = torch.sigmoid(self.fc4(x)) \n",
    "        return x\n",
    "    \n",
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 5)\n",
    "        self.fc2 = nn.Linear(5, 4)\n",
    "        self.fc3 = nn.Linear(4, 1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x)) \n",
    "        return x   \n",
    "\n",
    "net1 = Net1().cuda()\n",
    "net1.load_state_dict(torch.load('NN saves/4431_lr=0.03_MAE'))\n",
    "net1.eval()\n",
    "\n",
    "net2 = Net2().cuda()\n",
    "net2.load_state_dict(torch.load('NN saves/5541_NN'))\n",
    "net2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SRILMException",
     "evalue": "SRILM is not downloaded and compiled.Please follow the instructions in makesrilmcc",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSRILMException\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1e2a1d6a4f67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#lm = arpa.loadf('../../rsc/smoothedLM.arpa')[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#lm = pyn.ARPALanguageModel('../../rsc/smoothedLM.arpa')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpynLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSRILM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../rsc/smoothedLM.arpa'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pynlpl/lm/srilm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, n)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msrilmcc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             raise SRILMException(\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0;34m\"SRILM is not downloaded and compiled.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \"Please follow the instructions in makesrilmcc\")\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrilmcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLanguageModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSRILMException\u001b[0m: SRILM is not downloaded and compiled.Please follow the instructions in makesrilmcc"
     ]
    }
   ],
   "source": [
    "#lm = arpa.loadf('../../rsc/smoothedLM.arpa')[0]\n",
    "lm = pyn.ARPALanguageModel('../../rsc/smoothedLM.arpa')\n",
    "#lm = pynLM.SRILM('../../rsc/smoothedLM.arpa', 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LM probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen:\n",
      " Pgt(POSTS | JOBS, FOR) = 5.6950009387085187e-05\n",
      "\n",
      "Unseen:\n",
      "Pgt(MONEY | JOBS, FOR) = 0.0019743529819056757\n",
      "Pgt(CASH | JOBS, FOR) = 0.0019743529819056757\n"
     ]
    }
   ],
   "source": [
    "#r = 1\n",
    "\n",
    "print('Seen:\\nPgt(POSTS | JOBS, FOR) = ' + str(lm.p(\"JOBS FOR POSTS\")))\n",
    "\n",
    "\n",
    "print('\\nUnseen:\\nPgt(MONEY | JOBS, FOR) = ' + str(lm.p(\"JOBS FOR MONEY\")))\n",
    "print('Pgt(CASH | JOBS, FOR) = ' + str(lm.p(\"JOBS FOR CASH\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen:\n",
      "Pgt(POSTS | JOBS, FOR) = -8.790399507886116\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ARPALanguageModel' object has no attribute 'prob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7dc2ae0297ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nUnseen:\\nPgt(MONEY | JOBS, FOR) = '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"JOBS FOR HOS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pgt(CASH | JOBS, FOR) = '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"JOBS FOR CASH\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ARPALanguageModel' object has no attribute 'prob'"
     ]
    }
   ],
   "source": [
    "#r = 1\n",
    "\n",
    "print('Seen:\\nPgt(POSTS | JOBS, FOR) = ' + str(lm.scoreword(\"JOBS FOR POSTS\")))\n",
    "\n",
    "\n",
    "print('\\nUnseen:\\nPgt(MONEY | JOBS, FOR) = ' + str(lm.prob(\"JOBS FOR HOS\")))\n",
    "print('Pgt(CASH | JOBS, FOR) = ' + str(lm.prob(\"JOBS FOR CASH\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRIGRAM\n",
    "# JOBS FOR MONEY - 0\n",
    "# JOBS FOR POSTS - 2\n",
    "# JOBS FOR CASH - 1\n",
    "\n",
    "#PREFIX\n",
    "# JOBS FOR - 8\n",
    "\n",
    "#(N-1)-GRAM\n",
    "#FOR MONEY - 11\n",
    "#FOR CASH - 1\n",
    "#FOR POSTS - 2\n",
    "\n",
    "#(N-2)-GRAM\n",
    "# MONEY - 474\n",
    "# CASH - 125\n",
    "# POSTS - 83\n",
    "\n",
    "#PRE-PREFIX\n",
    "# JOBS - 147"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN discounted prob: 0.065711610019207\n",
      "Discounted prob from test set: 0.0375\n",
      "\n",
      "NN 'true' MLE: 0.15154613554477692\n",
      "MLE from test set: 0.125\n"
     ]
    }
   ],
   "source": [
    "#prefix - trigram - (n-1)-gram - (n-2)-gram - pre-prefix\n",
    "\n",
    "#jobs for posts\n",
    "inpt = torch.tensor([[8 , 1, 2 , 83 ]],device=device).float()\n",
    "inpt = 1/inpt\n",
    "out = float(net1(inpt))\n",
    "#print(float(out))\n",
    "\n",
    "print('NN discounted prob: ' + str(out))\n",
    "print('Discounted prob from test set: ' + str(0.3*1/8))\n",
    "\n",
    "\n",
    "\n",
    "inpt = torch.tensor([[8 , 1, 2 , 83 , 147]],device=device).float()\n",
    "inpt = 1/inpt\n",
    "out = float(net2(inpt))\n",
    "#print(float(out))\n",
    "\n",
    "print('\\nNN \\'true\\' MLE: ' + str(out))\n",
    "print('MLE from test set: ' + str(1/8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN discounted prob: 0.06568172574043274\n",
      "Discounted prob from test set: 0.0375\n",
      "\n",
      "NN 'true' MLE: 0.1473076343536377\n",
      "MLE from test set: 0.125\n"
     ]
    }
   ],
   "source": [
    "#prefix - trigram - (n-1)-gram - (n-2)-gram - pre-prefix\n",
    "\n",
    "#jobs for cash\n",
    "inpt = torch.tensor([[8 , 1, 1 , 125 ]],device=device).float()\n",
    "inpt = 1/inpt\n",
    "out = float(net1(inpt))\n",
    "#print(float(out))\n",
    "\n",
    "print('NN discounted prob: ' + str(out))\n",
    "print('Discounted prob from test set: ' + str(0.3*1/8))\n",
    "\n",
    "\n",
    "\n",
    "inpt = torch.tensor([[8 , 1, 1 , 125 , 147]],device=device).float()\n",
    "inpt = 1/inpt\n",
    "out = float(net2(inpt))\n",
    "#print(float(out))\n",
    "\n",
    "print('\\nNN \\'true\\' MLE: ' + str(out))\n",
    "print('MLE from test set: ' + str(1/8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN discounted prob: 6.656724167442007e-07\n",
      "Discounted prob from test set: 0.0\n",
      "\n",
      "NN 'true' MLE: 2.4396895241807215e-06\n",
      "MLE from test set: 0.0\n"
     ]
    }
   ],
   "source": [
    "#prefix - trigram - (n-1)-gram - (n-2)-gram - pre-prefix\n",
    "\n",
    "#jobs for money\n",
    "inpt = torch.tensor([[8, 0, 11 , 474 ]],device=device).float()\n",
    "inpt = 1/inpt\n",
    "out = float(net1(inpt))\n",
    "#print(float(out))\n",
    "\n",
    "print('NN discounted prob: ' + str(out))\n",
    "print('Discounted prob from test set: ' + str(0/8))\n",
    "\n",
    "\n",
    "\n",
    "inpt = torch.tensor([[8 , 0, 11 , 474 , 147]],device=device).float()\n",
    "inpt = 1/inpt\n",
    "out = float(net2(inpt))\n",
    "#print(float(out))\n",
    "\n",
    "print('\\nNN \\'true\\' MLE: ' + str(out))\n",
    "print('MLE from test set: ' + str(0/8))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
