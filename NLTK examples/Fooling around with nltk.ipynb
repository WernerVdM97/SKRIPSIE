{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import collections\n",
    "import unicodedata \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import inflect \n",
    "#This is a simple library for accomplishing \n",
    "#the natural language related tasks of generating plurals, \n",
    "#singular nouns, ordinals, and indefinite articles, and \n",
    "#(of most interest to us) converting numbers to words \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../corpus/bible.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.460659027099609\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pre_tokens = sent_tokenize(file)\n",
    "post_token = []\n",
    "\n",
    "# now loop over each sentence and tokenize it separately\n",
    "for sentence in pre_tokens:\n",
    "    post_token.append(word_tokenize(sentence))\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29743\n"
     ]
    }
   ],
   "source": [
    "print(len(post_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1853995323181152\n"
     ]
    }
   ],
   "source": [
    "#normalise tokens manually\n",
    "'''\n",
    "removing non ascii\n",
    "to lowercase\n",
    "remove punctuation\n",
    "replace numbers\n",
    "remove stopwords\n",
    "'''\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = replace_numbers(words)\n",
    "    #words = remove_stopwords(words)\n",
    "    return words\n",
    "\n",
    "start = time.time()\n",
    "data = []\n",
    "\n",
    "for x in range(len(post_token)):\n",
    "    data.append(normalize(post_token[x]))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['in', 'the', 'beginning', 'god', 'created', 'the', 'heaven', 'and', 'the', 'earth'], ['and', 'the', 'earth', 'was', 'without', 'form', 'and', 'void', 'and', 'darkness', 'was', 'upon', 'the', 'face', 'of', 'the', 'deep'], ['and', 'the', 'spirit', 'of', 'god', 'moved', 'upon', 'the', 'face', 'of', 'the', 'waters']]\n"
     ]
    }
   ],
   "source": [
    "print(data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# outdated: applicable if data is tokenized entirely, not per sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-561ce2fe07b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbiF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConditionalFreqDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbiF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconditions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nltk/probability.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cond_samples)\u001b[0m\n\u001b[1;32m   1864\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcond_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1868\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "bigrams = ngrams(data,2)\n",
    "\n",
    "biF=nltk.ConditionalFreqDist(bigrams)\n",
    "\n",
    "biF.conditions()\n",
    "biF.keys()\n",
    "print(biF['my'].most_common(10))\n",
    "\n",
    "biP = nltk.ConditionalProbDist(biF , nltk.MLEProbDist)\n",
    "print(biP['my'].prob('people')) #prob for people given previous word is my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-d7c1f40c298b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtriF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFreqDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrigrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtriF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nltk/probability.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \"\"\"\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mCounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# Cached number of samples in this FreqDist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected at most 1 arguments, got %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nltk/probability.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \"\"\"\n\u001b[1;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFreqDist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    620\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fast path when counter is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "trigrams = ngrams(data,3)\n",
    "\n",
    "triF = nltk.FreqDist(trigrams)\n",
    "\n",
    "triF.plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(triF.freq(('of','the','lord'))) #relative frequency estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smoothing is required for values where answer above is equal to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(triF.N()) #total trigrams in training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK LM intro, important to note that lm required data to be tokenized per sentence\n",
    "3 main steps: Building vocab, training(counting ngrams), output prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tips\n",
    ">>> import nltk\n",
    ">>> obs = 'the rain in spain falls mainly in the plains'.split()\n",
    ">>> lm = nltk.NgramModel(2, obs, estimator=nltk.MLEProbDist)\n",
    ">>> lm.prob('rain', 'the') #wrong\n",
    "0.0\n",
    ">>> lm.prob('rain', ['the']) #right\n",
    "0.5\n",
    ">>> lm.prob('spain', 'rain in') #wrong\n",
    "0.0\n",
    ">>> lm.prob('spain', ['rain in']) #wrong\n",
    "'''long exception'''\n",
    ">>> lm.prob('spain', ['rain', 'in']) #right\n",
    "1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package nltk.lm in nltk:\n",
      "\n",
      "NAME\n",
      "    nltk.lm\n",
      "\n",
      "DESCRIPTION\n",
      "    NLTK Language Modeling Module.\n",
      "    ------------------------------\n",
      "    \n",
      "    Currently this module covers only ngram language models, but it should be easy\n",
      "    to extend to neural models.\n",
      "    \n",
      "    \n",
      "    Preparing Data\n",
      "    ==============\n",
      "    \n",
      "    Before we train our ngram models it is necessary to make sure the data we put in\n",
      "    them is in the right format.\n",
      "    Let's say we have a text that is a list of sentences, where each sentence is\n",
      "    a list of strings. For simplicity we just consider a text consisting of\n",
      "    characters instead of words.\n",
      "    \n",
      "        >>> text = [['a', 'b', 'c'], ['a', 'c', 'd', 'c', 'e', 'f']]\n",
      "    \n",
      "    If we want to train a bigram model, we need to turn this text into bigrams.\n",
      "    Here's what the first sentence of our text would look like if we use a function\n",
      "    from NLTK for this.\n",
      "    \n",
      "        >>> from nltk.util import bigrams\n",
      "        >>> list(bigrams(text[0]))\n",
      "        [('a', 'b'), ('b', 'c')]\n",
      "    \n",
      "    Notice how \"b\" occurs both as the first and second member of different bigrams\n",
      "    but \"a\" and \"c\" don't? Wouldn't it be nice to somehow indicate how often sentences\n",
      "    start with \"a\" and end with \"c\"?\n",
      "    A standard way to deal with this is to add special \"padding\" symbols to the\n",
      "    sentence before splitting it into ngrams.\n",
      "    Fortunately, NLTK also has a function for that, let's see what it does to the\n",
      "    first sentence.\n",
      "    \n",
      "        >>> from nltk.util import pad_sequence\n",
      "        >>> list(pad_sequence(text[0],\n",
      "        ... pad_left=True,\n",
      "        ... left_pad_symbol=\"<s>\",\n",
      "        ... pad_right=True,\n",
      "        ... right_pad_symbol=\"</s>\",\n",
      "        ... n=2))\n",
      "        ['<s>', 'a', 'b', 'c', '</s>']\n",
      "    \n",
      "    Note the `n` argument, that tells the function we need padding for bigrams.\n",
      "    Now, passing all these parameters every time is tedious and in most cases they\n",
      "    can be safely assumed as defaults anyway.\n",
      "    Thus our module provides a convenience function that has all these arguments\n",
      "    already set while the other arguments remain the same as for `pad_sequence`.\n",
      "    \n",
      "        >>> from nltk.lm.preprocessing import pad_both_ends\n",
      "        >>> list(pad_both_ends(text[0], n=2))\n",
      "        ['<s>', 'a', 'b', 'c', '</s>']\n",
      "    \n",
      "    Combining the two parts discussed so far we get the following preparation steps\n",
      "    for one sentence.\n",
      "    \n",
      "        >>> list(bigrams(pad_both_ends(text[0], n=2)))\n",
      "        [('<s>', 'a'), ('a', 'b'), ('b', 'c'), ('c', '</s>')]\n",
      "    \n",
      "    To make our model more robust we could also train it on unigrams (single words)\n",
      "    as well as bigrams, its main source of information.\n",
      "    NLTK once again helpfully provides a function called `everygrams`.\n",
      "    While not the most efficient, it is conceptually simple.\n",
      "    \n",
      "    \n",
      "        >>> from nltk.util import everygrams\n",
      "        >>> padded_bigrams = list(pad_both_ends(text[0], n=2))\n",
      "        >>> list(everygrams(padded_bigrams, max_len=2))\n",
      "        [('<s>',),\n",
      "         ('a',),\n",
      "         ('b',),\n",
      "         ('c',),\n",
      "         ('</s>',),\n",
      "         ('<s>', 'a'),\n",
      "         ('a', 'b'),\n",
      "         ('b', 'c'),\n",
      "         ('c', '</s>')]\n",
      "    \n",
      "    We are almost ready to start counting ngrams, just one more step left.\n",
      "    During training and evaluation our model will rely on a vocabulary that\n",
      "    defines which words are \"known\" to the model.\n",
      "    To create this vocabulary we need to pad our sentences (just like for counting\n",
      "    ngrams) and then combine the sentences into one flat stream of words.\n",
      "    \n",
      "        >>> from nltk.lm.preprocessing import flatten\n",
      "        >>> list(flatten(pad_both_ends(sent, n=2) for sent in text))\n",
      "        ['<s>', 'a', 'b', 'c', '</s>', '<s>', 'a', 'c', 'd', 'c', 'e', 'f', '</s>']\n",
      "    \n",
      "    In most cases we want to use the same text as the source for both vocabulary\n",
      "    and ngram counts.\n",
      "    Now that we understand what this means for our preprocessing, we can simply import\n",
      "    a function that does everything for us.\n",
      "    \n",
      "        >>> from nltk.lm.preprocessing import padded_everygram_pipeline\n",
      "        >>> train, vocab = padded_everygram_pipeline(2, text)\n",
      "    \n",
      "    So as to avoid re-creating the text in memory, both `train` and `vocab` are lazy\n",
      "    iterators. They are evaluated on demand at training time.\n",
      "    \n",
      "    \n",
      "    Training\n",
      "    ========\n",
      "    Having prepared our data we are ready to start training a model.\n",
      "    As a simple example, let us train a Maximum Likelihood Estimator (MLE).\n",
      "    We only need to specify the highest ngram order to instantiate it.\n",
      "    \n",
      "        >>> from nltk.lm import MLE\n",
      "        >>> lm = MLE(2)\n",
      "    \n",
      "    This automatically creates an empty vocabulary...\n",
      "    \n",
      "        >>> len(lm.vocab)\n",
      "        0\n",
      "    \n",
      "    ... which gets filled as we fit the model.\n",
      "    \n",
      "        >>> lm.fit(train, vocab)\n",
      "        >>> print(lm.vocab)\n",
      "        <Vocabulary with cutoff=1 unk_label='<UNK>' and 9 items>\n",
      "        >>> len(lm.vocab)\n",
      "        9\n",
      "    \n",
      "    The vocabulary helps us handle words that have not occurred during training.\n",
      "    \n",
      "        >>> lm.vocab.lookup(text[0])\n",
      "        ('a', 'b', 'c')\n",
      "        >>> lm.vocab.lookup([\"aliens\", \"from\", \"Mars\"])\n",
      "        ('<UNK>', '<UNK>', '<UNK>')\n",
      "    \n",
      "    Moreover, in some cases we want to ignore words that we did see during training\n",
      "    but that didn't occur frequently enough, to provide us useful information.\n",
      "    You can tell the vocabulary to ignore such words.\n",
      "    To find out how that works, check out the docs for the `Vocabulary` class.\n",
      "    \n",
      "    \n",
      "    Using a Trained Model\n",
      "    =====================\n",
      "    When it comes to ngram models the training boils down to counting up the ngrams\n",
      "    from the training corpus.\n",
      "    \n",
      "        >>> print(lm.counts)\n",
      "        <NgramCounter with 2 ngram orders and 24 ngrams>\n",
      "    \n",
      "    This provides a convenient interface to access counts for unigrams...\n",
      "    \n",
      "        >>> lm.counts['a']\n",
      "        2\n",
      "    \n",
      "    ...and bigrams (in this case \"a b\")\n",
      "    \n",
      "        >>> lm.counts[['a']]['b']\n",
      "        1\n",
      "    \n",
      "    And so on. However, the real purpose of training a language model is to have it\n",
      "    score how probable words are in certain contexts.\n",
      "    This being MLE, the model returns the item's relative frequency as its score.\n",
      "    \n",
      "        >>> lm.score(\"a\")\n",
      "        0.15384615384615385\n",
      "    \n",
      "    Items that are not seen during training are mapped to the vocabulary's\n",
      "    \"unknown label\" token. This is \"<UNK>\" by default.\n",
      "    \n",
      "        >>> lm.score(\"<UNK>\") == lm.score(\"aliens\")\n",
      "        True\n",
      "    \n",
      "    Here's how you get the score for a word given some preceding context.\n",
      "    For example we want to know what is the chance that \"b\" is preceded by \"a\".\n",
      "    \n",
      "        >>> lm.score(\"b\", [\"a\"])\n",
      "        0.5\n",
      "    \n",
      "    To avoid underflow when working with many small score values it makes sense to\n",
      "    take their logarithm.\n",
      "    For convenience this can be done with the `logscore` method.\n",
      "    \n",
      "        >>> lm.logscore(\"a\")\n",
      "        -2.700439718141092\n",
      "    \n",
      "    Building on this method, we can also evaluate our model's cross-entropy and\n",
      "    perplexity with respect to sequences of ngrams.\n",
      "    \n",
      "        >>> test = [('a', 'b'), ('c', 'd')]\n",
      "        >>> lm.entropy(test)\n",
      "        1.292481250360578\n",
      "        >>> lm.perplexity(test)\n",
      "        2.449489742783178\n",
      "    \n",
      "    It is advisable to preprocess your test text exactly the same way as you did\n",
      "    the training text.\n",
      "    \n",
      "    One cool feature of ngram models is that they can be used to generate text.\n",
      "    \n",
      "        >>> lm.generate(1, random_seed=3)\n",
      "        '<s>'\n",
      "        >>> lm.generate(5, random_seed=3)\n",
      "        ['<s>', 'a', 'b', 'c', 'd']\n",
      "    \n",
      "    Provide `random_seed` if you want to consistently reproduce the same text all\n",
      "    other things being equal. Here we are using it to test the examples.\n",
      "    \n",
      "    You can also condition your generation on some preceding text with the `context`\n",
      "    argument.\n",
      "    \n",
      "        >>> lm.generate(5, text_seed=['c'], random_seed=3)\n",
      "        ['</s>', 'c', 'd', 'c', 'd']\n",
      "    \n",
      "    Note that an ngram model is restricted in how much preceding context it can\n",
      "    take into account. For example, a trigram model can only condition its output\n",
      "    on 2 preceding words. If you pass in a 4-word context, the first two words\n",
      "    will be ignored.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    api\n",
      "    counter\n",
      "    models\n",
      "    preprocessing\n",
      "    smoothing\n",
      "    util\n",
      "    vocabulary\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        nltk.lm.counter.NgramCounter\n",
      "        nltk.lm.vocabulary.Vocabulary\n",
      "    nltk.lm.api.LanguageModel(builtins.object)\n",
      "        nltk.lm.models.Lidstone\n",
      "            nltk.lm.models.Laplace\n",
      "        nltk.lm.models.MLE\n",
      "    nltk.lm.models.InterpolatedLanguageModel(nltk.lm.api.LanguageModel)\n",
      "        nltk.lm.models.KneserNeyInterpolated\n",
      "        nltk.lm.models.WittenBellInterpolated\n",
      "    \n",
      "    class KneserNeyInterpolated(InterpolatedLanguageModel)\n",
      "     |  Interpolated version of Kneser-Ney smoothing.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      KneserNeyInterpolated\n",
      "     |      InterpolatedLanguageModel\n",
      "     |      nltk.lm.api.LanguageModel\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, order, discount=0.1, **kwargs)\n",
      "     |      Creates new LanguageModel.\n",
      "     |      \n",
      "     |      :param vocabulary: If provided, this vocabulary will be used instead\n",
      "     |      of creating a new one when training.\n",
      "     |      :type vocabulary: `nltk.lm.Vocabulary` or None\n",
      "     |      :param counter: If provided, use this object to count ngrams.\n",
      "     |      :type vocabulary: `nltk.lm.NgramCounter` or None\n",
      "     |      :param ngrams_fn: If given, defines how sentences in training text are turned to ngram\n",
      "     |                        sequences.\n",
      "     |      :type ngrams_fn: function or None\n",
      "     |      :param pad_fn: If given, defines how senteces in training text are padded.\n",
      "     |      :type pad_fn: function or None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from InterpolatedLanguageModel:\n",
      "     |  \n",
      "     |  unmasked_score(self, word, context=None)\n",
      "     |      Score a word given some optional context.\n",
      "     |      \n",
      "     |      Concrete models are expected to provide an implementation.\n",
      "     |      Note that this method does not mask its arguments with the OOV label.\n",
      "     |      Use the `score` method for that.\n",
      "     |      \n",
      "     |      :param str word: Word for which we want the score\n",
      "     |      :param tuple(str) context: Context the word is in.\n",
      "     |      If `None`, compute unigram score.\n",
      "     |      :param context: tuple(str) or None\n",
      "     |      :rtype: float\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  context_counts(self, context)\n",
      "     |      Helper method for retrieving counts for a given context.\n",
      "     |      \n",
      "     |      Assumes context has been checked and oov words in it masked.\n",
      "     |      :type context: tuple(str) or None\n",
      "     |  \n",
      "     |  entropy(self, text_ngrams)\n",
      "     |      Calculate cross-entropy of model for given evaluation text.\n",
      "     |      \n",
      "     |      :param Iterable(tuple(str)) text_ngrams: A sequence of ngram tuples.\n",
      "     |      :rtype: float\n",
      "     |  \n",
      "     |  fit(self, text, vocabulary_text=None)\n",
      "     |      Trains the model on a text.\n",
      "     |      \n",
      "     |      :param text: Training text as a sequence of sentences.\n",
      "     |  \n",
      "     |  generate(self, num_words=1, text_seed=None, random_seed=None)\n",
      "     |      Generate words from the model.\n",
      "     |      \n",
      "     |      :param int num_words: How many words to generate. By default 1.\n",
      "     |      :param text_seed: Generation can be conditioned on preceding context.\n",
      "     |      :param random_seed: A random seed or an instance of `random.Random`. If provided,\n",
      "     |      makes the random sampling part of generation reproducible.\n",
      "     |      :return: One (str) word or a list of words generated from model.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> from nltk.lm import MLE\n",
      "     |      >>> lm = MLE(2)\n",
      "     |      >>> lm.fit([[(\"a\", \"b\"), (\"b\", \"c\")]], vocabulary_text=['a', 'b', 'c'])\n",
      "     |      >>> lm.fit([[(\"a\",), (\"b\",), (\"c\",)]])\n",
      "     |      >>> lm.generate(random_seed=3)\n",
      "     |      'a'\n",
      "     |      >>> lm.generate(text_seed=['a'])\n",
      "     |      'b'\n",
      "     |  \n",
      "     |  logscore(self, word, context=None)\n",
      "     |      Evaluate the log score of this word in this context.\n",
      "     |      \n",
      "     |      The arguments are the same as for `score` and `unmasked_score`.\n",
      "     |  \n",
      "     |  perplexity(self, text_ngrams)\n",
      "     |      Calculates the perplexity of the given text.\n",
      "     |      \n",
      "     |      This is simply 2 ** cross-entropy for the text, so the arguments are the same.\n",
      "     |  \n",
      "     |  score(self, word, context=None)\n",
      "     |      Masks out of vocab (OOV) words and computes their model score.\n",
      "     |      \n",
      "     |      For model-specific logic of calculating scores, see the `unmasked_score`\n",
      "     |      method.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Laplace(Lidstone)\n",
      "     |  Implements Laplace (add one) smoothing.\n",
      "     |  \n",
      "     |  Initialization identical to BaseNgramModel because gamma is always 1.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Laplace\n",
      "     |      Lidstone\n",
      "     |      nltk.lm.api.LanguageModel\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args, **kwargs)\n",
      "     |      Creates new LanguageModel.\n",
      "     |      \n",
      "     |      :param vocabulary: If provided, this vocabulary will be used instead\n",
      "     |      of creating a new one when training.\n",
      "     |      :type vocabulary: `nltk.lm.Vocabulary` or None\n",
      "     |      :param counter: If provided, use this object to count ngrams.\n",
      "     |      :type vocabulary: `nltk.lm.NgramCounter` or None\n",
      "     |      :param ngrams_fn: If given, defines how sentences in training text are turned to ngram\n",
      "     |                        sequences.\n",
      "     |      :type ngrams_fn: function or None\n",
      "     |      :param pad_fn: If given, defines how senteces in training text are padded.\n",
      "     |      :type pad_fn: function or None\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self, /)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Lidstone:\n",
      "     |  \n",
      "     |  unmasked_score(self, word, context=None)\n",
      "     |      Add-one smoothing: Lidstone or Laplace.\n",
      "     |      \n",
      "     |      To see what kind, look at `gamma` attribute on the class.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  context_counts(self, context)\n",
      "     |      Helper method for retrieving counts for a given context.\n",
      "     |      \n",
      "     |      Assumes context has been checked and oov words in it masked.\n",
      "     |      :type context: tuple(str) or None\n",
      "     |  \n",
      "     |  entropy(self, text_ngrams)\n",
      "     |      Calculate cross-entropy of model for given evaluation text.\n",
      "     |      \n",
      "     |      :param Iterable(tuple(str)) text_ngrams: A sequence of ngram tuples.\n",
      "     |      :rtype: float\n",
      "     |  \n",
      "     |  fit(self, text, vocabulary_text=None)\n",
      "     |      Trains the model on a text.\n",
      "     |      \n",
      "     |      :param text: Training text as a sequence of sentences.\n",
      "     |  \n",
      "     |  generate(self, num_words=1, text_seed=None, random_seed=None)\n",
      "     |      Generate words from the model.\n",
      "     |      \n",
      "     |      :param int num_words: How many words to generate. By default 1.\n",
      "     |      :param text_seed: Generation can be conditioned on preceding context.\n",
      "     |      :param random_seed: A random seed or an instance of `random.Random`. If provided,\n",
      "     |      makes the random sampling part of generation reproducible.\n",
      "     |      :return: One (str) word or a list of words generated from model.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> from nltk.lm import MLE\n",
      "     |      >>> lm = MLE(2)\n",
      "     |      >>> lm.fit([[(\"a\", \"b\"), (\"b\", \"c\")]], vocabulary_text=['a', 'b', 'c'])\n",
      "     |      >>> lm.fit([[(\"a\",), (\"b\",), (\"c\",)]])\n",
      "     |      >>> lm.generate(random_seed=3)\n",
      "     |      'a'\n",
      "     |      >>> lm.generate(text_seed=['a'])\n",
      "     |      'b'\n",
      "     |  \n",
      "     |  logscore(self, word, context=None)\n",
      "     |      Evaluate the log score of this word in this context.\n",
      "     |      \n",
      "     |      The arguments are the same as for `score` and `unmasked_score`.\n",
      "     |  \n",
      "     |  perplexity(self, text_ngrams)\n",
      "     |      Calculates the perplexity of the given text.\n",
      "     |      \n",
      "     |      This is simply 2 ** cross-entropy for the text, so the arguments are the same.\n",
      "     |  \n",
      "     |  score(self, word, context=None)\n",
      "     |      Masks out of vocab (OOV) words and computes their model score.\n",
      "     |      \n",
      "     |      For model-specific logic of calculating scores, see the `unmasked_score`\n",
      "     |      method.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Lidstone(nltk.lm.api.LanguageModel)\n",
      "     |  Provides Lidstone-smoothed scores.\n",
      "     |  \n",
      "     |  In addition to initialization arguments from BaseNgramModel also requires\n",
      "     |  a number by which to increase the counts, gamma.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Lidstone\n",
      "     |      nltk.lm.api.LanguageModel\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, gamma, *args, **kwargs)\n",
      "     |      Creates new LanguageModel.\n",
      "     |      \n",
      "     |      :param vocabulary: If provided, this vocabulary will be used instead\n",
      "     |      of creating a new one when training.\n",
      "     |      :type vocabulary: `nltk.lm.Vocabulary` or None\n",
      "     |      :param counter: If provided, use this object to count ngrams.\n",
      "     |      :type vocabulary: `nltk.lm.NgramCounter` or None\n",
      "     |      :param ngrams_fn: If given, defines how sentences in training text are turned to ngram\n",
      "     |                        sequences.\n",
      "     |      :type ngrams_fn: function or None\n",
      "     |      :param pad_fn: If given, defines how senteces in training text are padded.\n",
      "     |      :type pad_fn: function or None\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self, /)\n",
      "     |  \n",
      "     |  unmasked_score(self, word, context=None)\n",
      "     |      Add-one smoothing: Lidstone or Laplace.\n",
      "     |      \n",
      "     |      To see what kind, look at `gamma` attribute on the class.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  context_counts(self, context)\n",
      "     |      Helper method for retrieving counts for a given context.\n",
      "     |      \n",
      "     |      Assumes context has been checked and oov words in it masked.\n",
      "     |      :type context: tuple(str) or None\n",
      "     |  \n",
      "     |  entropy(self, text_ngrams)\n",
      "     |      Calculate cross-entropy of model for given evaluation text.\n",
      "     |      \n",
      "     |      :param Iterable(tuple(str)) text_ngrams: A sequence of ngram tuples.\n",
      "     |      :rtype: float\n",
      "     |  \n",
      "     |  fit(self, text, vocabulary_text=None)\n",
      "     |      Trains the model on a text.\n",
      "     |      \n",
      "     |      :param text: Training text as a sequence of sentences.\n",
      "     |  \n",
      "     |  generate(self, num_words=1, text_seed=None, random_seed=None)\n",
      "     |      Generate words from the model.\n",
      "     |      \n",
      "     |      :param int num_words: How many words to generate. By default 1.\n",
      "     |      :param text_seed: Generation can be conditioned on preceding context.\n",
      "     |      :param random_seed: A random seed or an instance of `random.Random`. If provided,\n",
      "     |      makes the random sampling part of generation reproducible.\n",
      "     |      :return: One (str) word or a list of words generated from model.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> from nltk.lm import MLE\n",
      "     |      >>> lm = MLE(2)\n",
      "     |      >>> lm.fit([[(\"a\", \"b\"), (\"b\", \"c\")]], vocabulary_text=['a', 'b', 'c'])\n",
      "     |      >>> lm.fit([[(\"a\",), (\"b\",), (\"c\",)]])\n",
      "     |      >>> lm.generate(random_seed=3)\n",
      "     |      'a'\n",
      "     |      >>> lm.generate(text_seed=['a'])\n",
      "     |      'b'\n",
      "     |  \n",
      "     |  logscore(self, word, context=None)\n",
      "     |      Evaluate the log score of this word in this context.\n",
      "     |      \n",
      "     |      The arguments are the same as for `score` and `unmasked_score`.\n",
      "     |  \n",
      "     |  perplexity(self, text_ngrams)\n",
      "     |      Calculates the perplexity of the given text.\n",
      "     |      \n",
      "     |      This is simply 2 ** cross-entropy for the text, so the arguments are the same.\n",
      "     |  \n",
      "     |  score(self, word, context=None)\n",
      "     |      Masks out of vocab (OOV) words and computes their model score.\n",
      "     |      \n",
      "     |      For model-specific logic of calculating scores, see the `unmasked_score`\n",
      "     |      method.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MLE(nltk.lm.api.LanguageModel)\n",
      "     |  Class for providing MLE ngram model scores.\n",
      "     |  \n",
      "     |  Inherits initialization from BaseNgramModel.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MLE\n",
      "     |      nltk.lm.api.LanguageModel\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self, /)\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self, /)\n",
      "     |  \n",
      "     |  unmasked_score(self, word, context=None)\n",
      "     |      Returns the MLE score for a word given a context.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |      - word is expcected to be a string\n",
      "     |      - context is expected to be something reasonably convertible to a tuple\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  __init__(self, order, vocabulary=None, counter=None)\n",
      "     |      Creates new LanguageModel.\n",
      "     |      \n",
      "     |      :param vocabulary: If provided, this vocabulary will be used instead\n",
      "     |      of creating a new one when training.\n",
      "     |      :type vocabulary: `nltk.lm.Vocabulary` or None\n",
      "     |      :param counter: If provided, use this object to count ngrams.\n",
      "     |      :type vocabulary: `nltk.lm.NgramCounter` or None\n",
      "     |      :param ngrams_fn: If given, defines how sentences in training text are turned to ngram\n",
      "     |                        sequences.\n",
      "     |      :type ngrams_fn: function or None\n",
      "     |      :param pad_fn: If given, defines how senteces in training text are padded.\n",
      "     |      :type pad_fn: function or None\n",
      "     |  \n",
      "     |  context_counts(self, context)\n",
      "     |      Helper method for retrieving counts for a given context.\n",
      "     |      \n",
      "     |      Assumes context has been checked and oov words in it masked.\n",
      "     |      :type context: tuple(str) or None\n",
      "     |  \n",
      "     |  entropy(self, text_ngrams)\n",
      "     |      Calculate cross-entropy of model for given evaluation text.\n",
      "     |      \n",
      "     |      :param Iterable(tuple(str)) text_ngrams: A sequence of ngram tuples.\n",
      "     |      :rtype: float\n",
      "     |  \n",
      "     |  fit(self, text, vocabulary_text=None)\n",
      "     |      Trains the model on a text.\n",
      "     |      \n",
      "     |      :param text: Training text as a sequence of sentences.\n",
      "     |  \n",
      "     |  generate(self, num_words=1, text_seed=None, random_seed=None)\n",
      "     |      Generate words from the model.\n",
      "     |      \n",
      "     |      :param int num_words: How many words to generate. By default 1.\n",
      "     |      :param text_seed: Generation can be conditioned on preceding context.\n",
      "     |      :param random_seed: A random seed or an instance of `random.Random`. If provided,\n",
      "     |      makes the random sampling part of generation reproducible.\n",
      "     |      :return: One (str) word or a list of words generated from model.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> from nltk.lm import MLE\n",
      "     |      >>> lm = MLE(2)\n",
      "     |      >>> lm.fit([[(\"a\", \"b\"), (\"b\", \"c\")]], vocabulary_text=['a', 'b', 'c'])\n",
      "     |      >>> lm.fit([[(\"a\",), (\"b\",), (\"c\",)]])\n",
      "     |      >>> lm.generate(random_seed=3)\n",
      "     |      'a'\n",
      "     |      >>> lm.generate(text_seed=['a'])\n",
      "     |      'b'\n",
      "     |  \n",
      "     |  logscore(self, word, context=None)\n",
      "     |      Evaluate the log score of this word in this context.\n",
      "     |      \n",
      "     |      The arguments are the same as for `score` and `unmasked_score`.\n",
      "     |  \n",
      "     |  perplexity(self, text_ngrams)\n",
      "     |      Calculates the perplexity of the given text.\n",
      "     |      \n",
      "     |      This is simply 2 ** cross-entropy for the text, so the arguments are the same.\n",
      "     |  \n",
      "     |  score(self, word, context=None)\n",
      "     |      Masks out of vocab (OOV) words and computes their model score.\n",
      "     |      \n",
      "     |      For model-specific logic of calculating scores, see the `unmasked_score`\n",
      "     |      method.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class NgramCounter(builtins.object)\n",
      "     |  Class for counting ngrams.\n",
      "     |  \n",
      "     |  Will count any ngram sequence you give it ;)\n",
      "     |  \n",
      "     |  First we need to make sure we are feeding the counter sentences of ngrams.\n",
      "     |  \n",
      "     |  >>> text = [[\"a\", \"b\", \"c\", \"d\"], [\"a\", \"c\", \"d\", \"c\"]]\n",
      "     |  >>> from nltk.util import ngrams\n",
      "     |  >>> text_bigrams = [ngrams(sent, 2) for sent in text]\n",
      "     |  >>> text_unigrams = [ngrams(sent, 1) for sent in text]\n",
      "     |  \n",
      "     |  The counting itself is very simple.\n",
      "     |  \n",
      "     |  >>> from nltk.lm import NgramCounter\n",
      "     |  >>> ngram_counts = NgramCounter(text_bigrams + text_unigrams)\n",
      "     |  \n",
      "     |  You can conveniently access ngram counts using standard python dictionary notation.\n",
      "     |  String keys will give you unigram counts.\n",
      "     |  \n",
      "     |  >>> ngram_counts['a']\n",
      "     |  2\n",
      "     |  >>> ngram_counts['aliens']\n",
      "     |  0\n",
      "     |  \n",
      "     |  If you want to access counts for higher order ngrams, use a list or a tuple.\n",
      "     |  These are treated as \"context\" keys, so what you get is a frequency distribution\n",
      "     |  over all continuations after the given context.\n",
      "     |  \n",
      "     |  >>> sorted(ngram_counts[['a']].items())\n",
      "     |  [('b', 1), ('c', 1)]\n",
      "     |  >>> sorted(ngram_counts[('a',)].items())\n",
      "     |  [('b', 1), ('c', 1)]\n",
      "     |  \n",
      "     |  This is equivalent to specifying explicitly the order of the ngram (in this case\n",
      "     |  2 for bigram) and indexing on the context.\n",
      "     |  >>> ngram_counts[2][('a',)] is ngram_counts[['a']]\n",
      "     |  True\n",
      "     |  \n",
      "     |  Note that the keys in `ConditionalFreqDist` cannot be lists, only tuples!\n",
      "     |  It is generally advisable to use the less verbose and more flexible square\n",
      "     |  bracket notation.\n",
      "     |  \n",
      "     |  To get the count of the full ngram \"a b\", do this:\n",
      "     |  \n",
      "     |  >>> ngram_counts[['a']]['b']\n",
      "     |  1\n",
      "     |  \n",
      "     |  Specifying the ngram order as a number can be useful for accessing all ngrams\n",
      "     |  in that order.\n",
      "     |  \n",
      "     |  >>> ngram_counts[2]\n",
      "     |  <ConditionalFreqDist with 4 conditions>\n",
      "     |  \n",
      "     |  The keys of this `ConditionalFreqDist` are the contexts we discussed earlier.\n",
      "     |  Unigrams can also be accessed with a human-friendly alias.\n",
      "     |  \n",
      "     |  >>> ngram_counts.unigrams is ngram_counts[1]\n",
      "     |  True\n",
      "     |  \n",
      "     |  Similarly to `collections.Counter`, you can update counts after initialization.\n",
      "     |  \n",
      "     |  >>> ngram_counts['e']\n",
      "     |  0\n",
      "     |  >>> ngram_counts.update([ngrams([\"d\", \"e\", \"f\"], 1)])\n",
      "     |  >>> ngram_counts['e']\n",
      "     |  1\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  N(self)\n",
      "     |      Returns grand total number of ngrams stored.\n",
      "     |      \n",
      "     |      This includes ngrams from all orders, so some duplication is expected.\n",
      "     |      :rtype: int\n",
      "     |      \n",
      "     |      >>> from nltk.lm import NgramCounter\n",
      "     |      >>> counts = NgramCounter([[(\"a\", \"b\"), (\"c\",), (\"d\", \"e\")]])\n",
      "     |      >>> counts.N()\n",
      "     |      3\n",
      "     |  \n",
      "     |  __contains__(self, item)\n",
      "     |  \n",
      "     |  __getitem__(self, item)\n",
      "     |      User-friendly access to ngram counts.\n",
      "     |  \n",
      "     |  __init__(self, ngram_text=None)\n",
      "     |      Creates a new NgramCounter.\n",
      "     |      \n",
      "     |      If `ngram_text` is specified, counts ngrams from it, otherwise waits for\n",
      "     |      `update` method to be called explicitly.\n",
      "     |      \n",
      "     |      :param ngram_text: Optional text containing senteces of ngrams, as for `update` method.\n",
      "     |      :type ngram_text: Iterable(Iterable(tuple(str))) or None\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self)\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self, /)\n",
      "     |  \n",
      "     |  update(self, ngram_text)\n",
      "     |      Updates ngram counts from `ngram_text`.\n",
      "     |      \n",
      "     |      Expects `ngram_text` to be a sequence of sentences (sequences).\n",
      "     |      Each sentence consists of ngrams as tuples of strings.\n",
      "     |      \n",
      "     |      :param Iterable(Iterable(tuple(str))) ngram_text: Text containing senteces of ngrams.\n",
      "     |      :raises TypeError: if the ngrams are not tuples.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Vocabulary(builtins.object)\n",
      "     |  Stores language model vocabulary.\n",
      "     |  \n",
      "     |  Satisfies two common language modeling requirements for a vocabulary:\n",
      "     |  - When checking membership and calculating its size, filters items\n",
      "     |    by comparing their counts to a cutoff value.\n",
      "     |  - Adds a special \"unknown\" token which unseen words are mapped to.\n",
      "     |  \n",
      "     |  >>> words = ['a', 'c', '-', 'd', 'c', 'a', 'b', 'r', 'a', 'c', 'd']\n",
      "     |  >>> from nltk.lm import Vocabulary\n",
      "     |  >>> vocab = Vocabulary(words, unk_cutoff=2)\n",
      "     |  \n",
      "     |  Tokens with counts greater than or equal to the cutoff value will\n",
      "     |  be considered part of the vocabulary.\n",
      "     |  \n",
      "     |  >>> vocab['c']\n",
      "     |  3\n",
      "     |  >>> 'c' in vocab\n",
      "     |  True\n",
      "     |  >>> vocab['d']\n",
      "     |  2\n",
      "     |  >>> 'd' in vocab\n",
      "     |  True\n",
      "     |  \n",
      "     |  Tokens with frequency counts less than the cutoff value will be considered not\n",
      "     |  part of the vocabulary even though their entries in the count dictionary are\n",
      "     |  preserved.\n",
      "     |  \n",
      "     |  >>> vocab['b']\n",
      "     |  1\n",
      "     |  >>> 'b' in vocab\n",
      "     |  False\n",
      "     |  >>> vocab['aliens']\n",
      "     |  0\n",
      "     |  >>> 'aliens' in vocab\n",
      "     |  False\n",
      "     |  \n",
      "     |  Keeping the count entries for seen words allows us to change the cutoff value\n",
      "     |  without having to recalculate the counts.\n",
      "     |  \n",
      "     |  >>> vocab2 = Vocabulary(vocab.counts, unk_cutoff=1)\n",
      "     |  >>> \"b\" in vocab2\n",
      "     |  True\n",
      "     |  \n",
      "     |  The cutoff value influences not only membership checking but also the result of\n",
      "     |  getting the size of the vocabulary using the built-in `len`.\n",
      "     |  Note that while the number of keys in the vocabulary's counter stays the same,\n",
      "     |  the items in the vocabulary differ depending on the cutoff.\n",
      "     |  We use `sorted` to demonstrate because it keeps the order consistent.\n",
      "     |  \n",
      "     |  >>> sorted(vocab2.counts)\n",
      "     |  ['-', 'a', 'b', 'c', 'd', 'r']\n",
      "     |  >>> sorted(vocab2)\n",
      "     |  ['-', '<UNK>', 'a', 'b', 'c', 'd', 'r']\n",
      "     |  >>> sorted(vocab.counts)\n",
      "     |  ['-', 'a', 'b', 'c', 'd', 'r']\n",
      "     |  >>> sorted(vocab)\n",
      "     |  ['<UNK>', 'a', 'c', 'd']\n",
      "     |  \n",
      "     |  In addition to items it gets populated with, the vocabulary stores a special\n",
      "     |  token that stands in for so-called \"unknown\" items. By default it's \"<UNK>\".\n",
      "     |  \n",
      "     |  >>> \"<UNK>\" in vocab\n",
      "     |  True\n",
      "     |  \n",
      "     |  We can look up words in a vocabulary using its `lookup` method.\n",
      "     |  \"Unseen\" words (with counts less than cutoff) are looked up as the unknown label.\n",
      "     |  If given one word (a string) as an input, this method will return a string.\n",
      "     |  \n",
      "     |  >>> vocab.lookup(\"a\")\n",
      "     |  'a'\n",
      "     |  >>> vocab.lookup(\"aliens\")\n",
      "     |  '<UNK>'\n",
      "     |  \n",
      "     |  If given a sequence, it will return an tuple of the looked up words.\n",
      "     |  \n",
      "     |  >>> vocab.lookup([\"p\", 'a', 'r', 'd', 'b', 'c'])\n",
      "     |  ('<UNK>', 'a', '<UNK>', 'd', '<UNK>', 'c')\n",
      "     |  \n",
      "     |  It's possible to update the counts after the vocabulary has been created.\n",
      "     |  The interface follows that of `collections.Counter`.\n",
      "     |  \n",
      "     |  >>> vocab['b']\n",
      "     |  1\n",
      "     |  >>> vocab.update([\"b\", \"b\", \"c\"])\n",
      "     |  >>> vocab['b']\n",
      "     |  3\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __contains__(self, item)\n",
      "     |      Only consider items with counts GE to cutoff as being in the\n",
      "     |      vocabulary.\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __getitem__(self, item)\n",
      "     |  \n",
      "     |  __init__(self, counts=None, unk_cutoff=1, unk_label='<UNK>')\n",
      "     |      Create a new Vocabulary.\n",
      "     |      \n",
      "     |      :param counts: Optional iterable or `collections.Counter` instance to\n",
      "     |                     pre-seed the Vocabulary. In case it is iterable, counts\n",
      "     |                     are calculated.\n",
      "     |      :param int unk_cutoff: Words that occur less frequently than this value\n",
      "     |                             are not considered part of the vocabulary.\n",
      "     |      :param unk_label: Label for marking words not part of vocabulary.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Building on membership check define how to iterate over\n",
      "     |      vocabulary.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Computing size of vocabulary reflects the cutoff.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__ = __str__(self)\n",
      "     |  \n",
      "     |  lookup(self, words)\n",
      "     |      Look up one or more words in the vocabulary.\n",
      "     |      \n",
      "     |      If passed one word as a string will return that word or `self.unk_label`.\n",
      "     |      Otherwise will assume it was passed a sequence of words, will try to look\n",
      "     |      each of them up and return an iterator over the looked up words.\n",
      "     |      \n",
      "     |      :param words: Word(s) to look up.\n",
      "     |      :type words: Iterable(str) or str\n",
      "     |      :rtype: generator(str) or str\n",
      "     |      :raises: TypeError for types other than strings or iterables\n",
      "     |      \n",
      "     |      >>> from nltk.lm import Vocabulary\n",
      "     |      >>> vocab = Vocabulary([\"a\", \"b\", \"c\", \"a\", \"b\"], unk_cutoff=2)\n",
      "     |      >>> vocab.lookup(\"a\")\n",
      "     |      'a'\n",
      "     |      >>> vocab.lookup(\"aliens\")\n",
      "     |      '<UNK>'\n",
      "     |      >>> vocab.lookup([\"a\", \"b\", \"c\", [\"x\", \"b\"]])\n",
      "     |      ('a', 'b', '<UNK>', ('<UNK>', 'b'))\n",
      "     |  \n",
      "     |  unicode_repr = __repr__(self, /)\n",
      "     |  \n",
      "     |  update(self, *counter_args, **counter_kwargs)\n",
      "     |      Update vocabulary counts.\n",
      "     |      \n",
      "     |      Wraps `collections.Counter.update` method.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  cutoff\n",
      "     |      Cutoff value.\n",
      "     |      \n",
      "     |      Items with count below this value are not considered part of vocabulary.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class WittenBellInterpolated(InterpolatedLanguageModel)\n",
      "     |  Interpolated version of Witten-Bell smoothing.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WittenBellInterpolated\n",
      "     |      InterpolatedLanguageModel\n",
      "     |      nltk.lm.api.LanguageModel\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, order, **kwargs)\n",
      "     |      Creates new LanguageModel.\n",
      "     |      \n",
      "     |      :param vocabulary: If provided, this vocabulary will be used instead\n",
      "     |      of creating a new one when training.\n",
      "     |      :type vocabulary: `nltk.lm.Vocabulary` or None\n",
      "     |      :param counter: If provided, use this object to count ngrams.\n",
      "     |      :type vocabulary: `nltk.lm.NgramCounter` or None\n",
      "     |      :param ngrams_fn: If given, defines how sentences in training text are turned to ngram\n",
      "     |                        sequences.\n",
      "     |      :type ngrams_fn: function or None\n",
      "     |      :param pad_fn: If given, defines how senteces in training text are padded.\n",
      "     |      :type pad_fn: function or None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from InterpolatedLanguageModel:\n",
      "     |  \n",
      "     |  unmasked_score(self, word, context=None)\n",
      "     |      Score a word given some optional context.\n",
      "     |      \n",
      "     |      Concrete models are expected to provide an implementation.\n",
      "     |      Note that this method does not mask its arguments with the OOV label.\n",
      "     |      Use the `score` method for that.\n",
      "     |      \n",
      "     |      :param str word: Word for which we want the score\n",
      "     |      :param tuple(str) context: Context the word is in.\n",
      "     |      If `None`, compute unigram score.\n",
      "     |      :param context: tuple(str) or None\n",
      "     |      :rtype: float\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  context_counts(self, context)\n",
      "     |      Helper method for retrieving counts for a given context.\n",
      "     |      \n",
      "     |      Assumes context has been checked and oov words in it masked.\n",
      "     |      :type context: tuple(str) or None\n",
      "     |  \n",
      "     |  entropy(self, text_ngrams)\n",
      "     |      Calculate cross-entropy of model for given evaluation text.\n",
      "     |      \n",
      "     |      :param Iterable(tuple(str)) text_ngrams: A sequence of ngram tuples.\n",
      "     |      :rtype: float\n",
      "     |  \n",
      "     |  fit(self, text, vocabulary_text=None)\n",
      "     |      Trains the model on a text.\n",
      "     |      \n",
      "     |      :param text: Training text as a sequence of sentences.\n",
      "     |  \n",
      "     |  generate(self, num_words=1, text_seed=None, random_seed=None)\n",
      "     |      Generate words from the model.\n",
      "     |      \n",
      "     |      :param int num_words: How many words to generate. By default 1.\n",
      "     |      :param text_seed: Generation can be conditioned on preceding context.\n",
      "     |      :param random_seed: A random seed or an instance of `random.Random`. If provided,\n",
      "     |      makes the random sampling part of generation reproducible.\n",
      "     |      :return: One (str) word or a list of words generated from model.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      >>> from nltk.lm import MLE\n",
      "     |      >>> lm = MLE(2)\n",
      "     |      >>> lm.fit([[(\"a\", \"b\"), (\"b\", \"c\")]], vocabulary_text=['a', 'b', 'c'])\n",
      "     |      >>> lm.fit([[(\"a\",), (\"b\",), (\"c\",)]])\n",
      "     |      >>> lm.generate(random_seed=3)\n",
      "     |      'a'\n",
      "     |      >>> lm.generate(text_seed=['a'])\n",
      "     |      'b'\n",
      "     |  \n",
      "     |  logscore(self, word, context=None)\n",
      "     |      Evaluate the log score of this word in this context.\n",
      "     |      \n",
      "     |      The arguments are the same as for `score` and `unmasked_score`.\n",
      "     |  \n",
      "     |  perplexity(self, text_ngrams)\n",
      "     |      Calculates the perplexity of the given text.\n",
      "     |      \n",
      "     |      This is simply 2 ** cross-entropy for the text, so the arguments are the same.\n",
      "     |  \n",
      "     |  score(self, word, context=None)\n",
      "     |      Masks out of vocab (OOV) words and computes their model score.\n",
      "     |      \n",
      "     |      For model-specific logic of calculating scores, see the `unmasked_score`\n",
      "     |      method.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from nltk.lm.api.LanguageModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['Vocabulary', 'NgramCounter', 'MLE', 'Lidstone', 'Laplace',...\n",
      "\n",
      "FILE\n",
      "    /home/werner/.local/lib/python3.6/site-packages/nltk/lm/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk import lm\n",
    "help(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'b', 'c']]\n",
      "[('a', 'b'), ('b', 'c')]\n"
     ]
    }
   ],
   "source": [
    "#from nltk.model import build_vocabulary <----- outdated, package replaced\n",
    "\n",
    "text = [['a', 'b', 'c'], ['a', 'c', 'd', 'c', 'e', 'f']]\n",
    "print(text[:1])\n",
    "print(list(ngrams(text[0],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "#building vocab\n",
    "train, vocab = padded_everygram_pipeline(2, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Vocabulary with cutoff=1 unk_label='<UNK>' and 9 items>\n"
     ]
    }
   ],
   "source": [
    "from nltk.lm import MLE\n",
    "#training\n",
    "lm = MLE(2) #highest ngram in paramater. Instantiation creates empty vocab\n",
    "lm.fit(train, vocab)\n",
    "print(lm.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NgramCounter with 2 ngram orders and 24 ngrams>\n",
      "2\n",
      "0.15384615384615385\n",
      "-2.700439718141092\n",
      "1\n",
      "0.5\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "#using model\n",
    "print(lm.counts)\n",
    "\n",
    "#counting unigrams with a and displaying its score\n",
    "print(lm.counts['a'])\n",
    "print(lm.score('a'))\n",
    "print(lm.logscore('a'))\n",
    "#counting bigrams with a b\n",
    "print(lm.counts[['a']]['b'])\n",
    "\n",
    "#chance for b given previous word was a\n",
    "print(lm.score('b', ['a']))\n",
    "#or using log domain\n",
    "print(lm.logscore('b',['a']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This being MLE, the model returns the item’s relative frequency as its score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perplexity and entropy\n",
    ">>> test = [('a', 'b'), ('c', 'd')]\n",
    ">>> lm.entropy(test)\n",
    "1.292481250360578\n",
    ">>> lm.perplexity(test)\n",
    "2.449489742783178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'c', '</s>', 'e', 'f', '</s>', 'e', 'f']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating random sentences\n",
    "lm.generate(8, random_seed=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# apply this on larger corpus still bigrams do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import lm\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempData = [['awe','hierdie','is','my','toets','data'],['ek','hoop','dit', 'werk'],['as','dit','nie','werk','nie'],['is','ek','fucked'],['so','kom','ons','hoop','vir','die','beste']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['awe', 'hierdie', 'is', 'my', 'toets', 'data'], ['ek', 'hoop', 'dit', 'werk'], ['as', 'dit', 'nie', 'werk', 'nie'], ['is', 'ek', 'fucked'], ['so', 'kom', 'ons', 'hoop', 'vir', 'die', 'beste'], ['hos', 'kom', 'ons', 'kyk']]\n"
     ]
    }
   ],
   "source": [
    "tempData.append(['hos','kom','ons','kyk'])\n",
    "print(tempData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In the beginning God created the heaven and the earth.', 'And the earth was without form, and void; and darkness was upon the face of the deep.', 'And the Spirit of God moved upon the face of the waters.']\n"
     ]
    }
   ],
   "source": [
    "print(pre_tokens[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['In', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the', 'earth', '.'], ['And', 'the', 'earth', 'was', 'without', 'form', ',', 'and', 'void', ';', 'and', 'darkness', 'was', 'upon', 'the', 'face', 'of', 'the', 'deep', '.'], ['And', 'the', 'Spirit', 'of', 'God', 'moved', 'upon', 'the', 'face', 'of', 'the', 'waters', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(post_token[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['in', 'the', 'beginning', 'god', 'created', 'the', 'heaven', 'and', 'the', 'earth'], ['and', 'the', 'earth', 'was', 'without', 'form', 'and', 'void', 'and', 'darkness', 'was', 'upon', 'the', 'face', 'of', 'the', 'deep'], ['and', 'the', 'spirit', 'of', 'god', 'moved', 'upon', 'the', 'face', 'of', 'the', 'waters']]\n"
     ]
    }
   ],
   "source": [
    "print(data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('in', 'the'), ('the', 'beginning'), ('beginning', 'god'), ('god', 'created'), ('created', 'the'), ('the', 'heaven'), ('heaven', 'and'), ('and', 'the'), ('the', 'earth')]\n"
     ]
    }
   ],
   "source": [
    "print(list(ngrams(data[0],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2, vocab2 = padded_everygram_pipeline(2,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.936531066894531\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "start = time.time()\n",
    "lm2 = MLE(2) #highest ngram in paramater. Instantiation creates empty vocab\n",
    "lm2.fit(train2, vocab2)\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['children',\n",
       " 'of',\n",
       " 'juda',\n",
       " 'were',\n",
       " 'of',\n",
       " 'babylon',\n",
       " '</s>',\n",
       " 'then',\n",
       " 'he',\n",
       " 'had']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm2.generate(10, random_seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Vocabulary with cutoff=1 unk_label='<UNK>' and 12564 items>\n"
     ]
    }
   ],
   "source": [
    "print(lm2.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets try trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3, vocab3 = padded_everygram_pipeline(3,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.3253014087677\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "start = time.time()\n",
    "lm3 = MLE(3) #highest ngram in paramater. Instantiation creates empty vocab\n",
    "lm3.fit(train3, vocab3)\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['where', 'we', 'abode', 'in', 'the', 'second', 'time', 'and', 'that', 'they']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm3.generate(10, random_seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Vocabulary with cutoff=1 unk_label='<UNK>' and 12564 items>\n",
      "<NgramCounter with 3 ngram orders and 2642466 ngrams>\n"
     ]
    }
   ],
   "source": [
    "print(lm3.vocab)\n",
    "print(lm3.counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finding distributions, however recalculates ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import everygrams\n",
    "from nltk.lm import NgramCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.342249870300293\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb41c209c18>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "tempdata = [item for sublist in data for item in sublist] #flatten list\n",
    "all_ngrams = everygrams(tempdata,max_len=3)\n",
    "fd = nltk.FreqDist(all_ngrams)\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)\n",
    "fd.plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.240858793258667\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "text_bigrams = [ngrams(sent, 2) for sent in data]\n",
    "text_unigrams = [ngrams(sent, 1) for sent in data]\n",
    "text_trigrams = [ngrams(sent,3) for sent in data]\n",
    "\n",
    "ngram_counts = NgramCounter(text_bigrams + text_unigrams + text_trigrams)\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NgramCounter with 3 ngram orders and 2285676 ngrams>\n",
      "0.06503057479858398\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(ngram_counts)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ngram in \n",
    "ConFD = ConditionalFreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb410fd5b70>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigramDist = nltk.FreqDist(ngrams(tempdata,3))\n",
    "trigramDist.plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329932\n"
     ]
    }
   ],
   "source": [
    "print(trigramDist.r_Nr()[1]) #number of elemtents that apperar n times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1774.9999999999998\n"
     ]
    }
   ],
   "source": [
    "print(trigramDist.freq(('of','the','lord'))*trigramDist.N())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(trigramDist.r_Nr()[1775]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329932\n"
     ]
    }
   ],
   "source": [
    "print(len(trigramDist.hapaxes())) #hapaxes() return number of times an ngrams appears once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb40d9cb5c0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.plot(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good turing intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For unseen ngrams:\n",
    "$$ C_0\\cdot q_0 = \\frac{C_1}{N_\\sum} $$\n",
    "\n",
    "where $ C_0\\cdot q_0 $ is the probability of occurence of any unseen n-gram. $C_1$ is the number of n-grams occuring one time in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import SimpleGoodTuringProbDist as GT\n",
    "smoothedFD = GT(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the',)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothedFD.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180637.69184230312"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothedFD.smoothedNr(1) #return samples that appear n times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00040677520743009026\n",
      "0.00040545353472227374\n",
      "0.0\n",
      "0.1806317732704053\n"
     ]
    }
   ],
   "source": [
    "print(fd.freq(('unto','them')))\n",
    "print(smoothedFD.prob(('unto','them')))\n",
    "\n",
    "print(fd.freq(('lol')))  #prob of ngram\n",
    "print(smoothedFD.prob(('lol')))#smoothed prob of ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the',)\n",
      "0.026858200054607803\n"
     ]
    }
   ],
   "source": [
    "print(smoothedFD.max())\n",
    "print(smoothedFD.prob(('the',)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1806317732704053\n"
     ]
    }
   ],
   "source": [
    "print(fd.r_Nr()[1]/fd.N()) #prob of unseen ngram according to good turing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
