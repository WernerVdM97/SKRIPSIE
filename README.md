# This repository includes:
## Fisrt NN
  - Feature extraction given a file containing n-grams with their counts
  - Training of a neural network to produce a discounted probability for each n-gram
  - Rewriting these probabilties to an existing unsmoothed language model in ARPA format
  
## Second NN
  - Feature extraction given a file containing n-grams with their counts
  - Training of a neural network to produce a "true" MLE for each n-gram
  - Rewriting these probabilties and discounting them to an existing unsmoothed language model in ARPA format
 

Other files included are examples of basic interactions with neural networks and language modeling
